{"section":{"id":"9","section_name":"REVIEWS & RATINGS","default_issue_section":"9","landscape_view":"toc-landscape.html","portrait_view":"toc-portrait.html","title_color":"FFFFFF","description":"","default_landscape":null,"default_portrait":null,"priority":"9","cover_video":null,"cover_image":null,"order":"9","children_count":0,"stories":[{"id":"zinio_3_100340926_1439381005.0875","title":"Hard-core hardware: We stuffed this PC with 128GB of cutting-edge DDR4 RAM","sub_title":"In this section, hardware & software go through rigorous testing.","author":[{"id":"0","name":"GORDON MAH UNG","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"TESTED IN PCWORLD LABS","intro":"The 64GB barrier in system memory is now broken by DDR4 RAM in Intel’s Haswell-E. Watch us tear down that wall.","body":"<p class=\"byline\"><b>BY GORDON MAH UNG</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0058-012/3225-1-eng-GB/f0058-012.jpg\" width=\"873\" height=\"629\"  style=\"border: 0px  ;\" alt=\"f0058-01\" title=\"f0058-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>H</b>umans like to celebrate barriers being broken. The speed of sound. The first 1GHz processor, or 1TB hard drive.</p>\n<p>So get ready to pop the California sparkling wine, because we just smashed right through the 64GB system RAM barrier.</p>\n<p>That barrier, if you didn’t know, has vexed consumer computing for years now. Mainstream desktop PCs have all featured four slots for a maximum of 32GB of DDR3 RAM. At the high end, prosumer PCs doubled that to eight slots for a maximum of 64GB DDR3.</p>\n<p>With the move last year to DDR4 RAM in Intel’s Haswell-E, we were promised we’d finally break the 64GB mark. That time has come.</p>\n<p>Both Corsair and Kingston recently announced 128GB memory kits using 16GB DDR4 memory modules. We had to try one out.</p>\n<h3><b>What made this possible</b></h3><p>If you’re wondering why we’ve been locked in at 64GB for so long, it’s mostly due to the technology and process changes. DDR3 modules topped out at 8GB, in what’s typically called an unbuffered DIMM. You could actually get higher-capacity modules in DDR3, but they were only in registered or buffered DIMM. These memory modules are meant for servers or workstations, which typically cost an arm and a leg and run at much slower speeds, because they sacrifice density for reliability.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0059-012/3218-1-eng-GB/f0059-012.jpg\" width=\"878\" height=\"497\"  style=\"border: 0px  ;\" alt=\"f0059-01\" title=\"f0059-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>Watch the video at <a href=\"http://go.pcworld.com/128gbramvid\" target=\"_self\">go.pcworld.com/128gbramvid</a></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0060-012/3211-1-eng-GB/f0060-012.jpg\" width=\"732\" height=\"567\"  style=\"border: 0px  ;\" alt=\"f0060-01\" title=\"f0060-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Here’s what</b> 128GB of DDR4 looks like.</p>\n</figcaption>\n    \n    \n    \n    </div><p>The move to DDR4 last year with Intel’s Haswell-E CPU also promised higher-density chips. While DDR3 maxed out at 8GB, DDR4 now maxes out at 16GB per module.</p>\n<h3><b>Corsair Dominator Platinum</b></h3><p>To break the barrier, we reached out to Corsair for its 128GB kit (<a href=\"http://go.pcworld.com/corsair128gbram\" target=\"_self\">go.pcworld.com/corsair128gbram</a>). The company actually has three speeds: DDR4/2800, DDR4/2666 and DDR4/2400 at the Platinum level. The kit we used was the DDR4/2400, and it comprises eight 16GB modules. It comes in a matched set with two heat-sink fans. The module’s not cheap: The fastest DDR4/2800 set is $2,120, while the two lower-speed kits are $1,980. In true computer tradition, though, prices have already begun to fall. Corsair has since released its Vengeance LPX line at the same density and speed for $1,600.</p>\n<h3><b>What you need</b></h3><p>Not everyone can get to 128GB of RAM. Obviously, you need eight memory slots. You’ll also need a CPU that supports DDR4, but you don’t need a $1,000 Xeon or Core i7-5960X CPU. For this particular test I used Intel’s cheapest Haswell-E CPU, a Core i7-5820K. The final ingredient that you’ll need is a motherboard whose BIOS supports 128GB of RAM.</p>\n<p>When I first plugged the 128GB of RAM into our Asus X99 Deluxe/U3.1 board and threw the switch, it wouldn’t boot. Only after obtaining a beta BIOS from Asus would the board POST. The good news is, I’m told by Asus that it expects to roll out support across its X99 board lineup as we speak. I expect other motherboards to support 128GB of RAM, too, as the modules become more common.</p>\n<p>Once I updated the board to the latest BIOS, all went as expected without any hitches. The OS I used on our PC was Windows 8.1 Enterprise. If you still don’t believe I got the bottom-feeder Core i7-5820K to work with 128GB of RAM, here’s proof.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0061-012/3204-1-eng-GB/f0061-012.jpg\" width=\"593\" height=\"436\"  style=\"border: 0px  ;\" alt=\"f0061-01\" title=\"f0061-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>One of the first</b> 128GB DDR4 kits out is Corsair’s Dominator Platinum that’ll set you back $1,980.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>Uhh, now what?</b></h3><p>I’ll admit, I was giddy firing up a PC with 128GB of RAM in it, but once I was booted I experienced a “now what” moment of doubt. Few people need more than 16GB of RAM, and some can even get by with 8. Outside of the 1-percenters who may need 64GB of RAM for extreme Photoshop, virtualization, or multitasking, it’s just not needed.</p>\n<p>To make use of this glorious amount of hardware, I settled on creating one massive RAM disk. RAM disks use your system’s RAM to simulate a storage “disk.” They’ve been around for years but typically are far smaller due to the constraints of memory. Not everyone needs a RAM disk, but if you need access to temporary storage that puts even the most powerful SSDs to shame, a RAM disk is the way to do it.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0062-012/3197-1-eng-GB/f0062-012.jpg\" width=\"597\" height=\"719\"  style=\"border: 0px  ;\" alt=\"f0062-01\" title=\"f0062-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>We needed a</b> beta BIOS for the Asus X99 Deluxe U3.1 to get the 128GB of RAM working in our system.</p>\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0063-012/3190-1-eng-GB/f0063-012.jpg\" width=\"591\" height=\"588\"  style=\"border: 0px  ;\" alt=\"f0063-01\" title=\"f0063-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>I fired up Softperfect RAM disk and dialed in a 100GB RAM disk. Here’s what’s so great about the RAM I had: Even with a 100GB RAM disk, I had 28GB or so of memory left to work with.</p>\n<p>To find out just how fast this RAM disk could be, I ran Crystal Disk Mark. As you can see, the performance puts any SSD to shame. The mighty Intel 750-series SSD, for example, has a sequential read speed of maybe 2.7GBps. The RAM disk was hitting 8.7GBps.</p>\n<p>RAM disks have one pretty big downside: if there’s a sudden power outage or serious BSOD, kiss goodbye anything you had in the RAM disk that wasn’t previously saved. It’s gone baby, gone.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0064-012/3183-1-eng-GB/f0064-012.jpg\" width=\"411\" height=\"374\"  style=\"border: 0px  ;\" alt=\"f0064-01\" title=\"f0064-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>It’s obvious I’m reaching for use cases for this much RAM, but there are people out there who legitimately need this capacity. It’s just not for 99 percent of us. What this really is about, though, is finally breaking through the 64GB barrier</p>\n<p>Yes, 128GB of system RAM seems silly, but if you dial back the clock, people used to say that about 16MB of RAM and 1GB of RAM. One day, I can say with confidence, we’ll look back and laugh at how silly we were to be in awe of 128GB of RAM—when we’re all running 1TB and counting.</p>\n","layout":{"landscape":{"id":"am-landscape-18","link":"rr_article_02-l.twig"},"portrait":{"id":"am-portrait-18","link":"rr_article_02.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381008.7165","name":"f0058-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0058-012/3225-1-eng-GB/f0058-012_story_img_size_768x0.jpg","portrait":true,"width":"1066","height":"768","legacy_id":"434","is_default":true},{"id":"zinio_100340926_image_0_1439381008.7165","name":"f0058-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0058-012/3225-1-eng-GB/f0058-012_story_img_size_768x0.jpg","portrait":false,"width":"1066","height":"768","legacy_id":"434","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_6_1439381005.2263","name":"f0064-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0064-012/3183-1-eng-GB/f0064-012.jpg","portrait":true,"width":"411","height":"374","legacy_id":"428"},{"id":"zinio_100340926_image_6_1439381005.2263","name":"f0064-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0064-012/3183-1-eng-GB/f0064-012.jpg","portrait":false,"width":"411","height":"374","legacy_id":"428"},{"id":"zinio_100340926_image_5_1439381005.7625","name":"f0063-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0063-012/3190-1-eng-GB/f0063-012.jpg","portrait":true,"width":"591","height":"588","legacy_id":"429"},{"id":"zinio_100340926_image_5_1439381005.7625","name":"f0063-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0063-012/3190-1-eng-GB/f0063-012.jpg","portrait":false,"width":"591","height":"588","legacy_id":"429"},{"id":"zinio_100340926_image_4_1439381006.3539","name":"f0062-01","source":"","caption":"<p><b>We needed a</b> beta BIOS for the Asus X99 Deluxe U3.1 to get the 128GB of RAM working in our system.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0062-012/3197-1-eng-GB/f0062-012.jpg","portrait":true,"width":"597","height":"719","legacy_id":"430"},{"id":"zinio_100340926_image_4_1439381006.3539","name":"f0062-01","source":"","caption":"<p><b>We needed a</b> beta BIOS for the Asus X99 Deluxe U3.1 to get the 128GB of RAM working in our system.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0062-012/3197-1-eng-GB/f0062-012.jpg","portrait":false,"width":"597","height":"719","legacy_id":"430"},{"id":"zinio_100340926_image_3_1439381006.9768","name":"f0061-01","source":"","caption":"<p><b>One of the first</b> 128GB DDR4 kits out is Corsair’s Dominator Platinum that’ll set you back $1,980.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0061-012/3204-1-eng-GB/f0061-012.jpg","portrait":true,"width":"593","height":"436","legacy_id":"431"},{"id":"zinio_100340926_image_3_1439381006.9768","name":"f0061-01","source":"","caption":"<p><b>One of the first</b> 128GB DDR4 kits out is Corsair’s Dominator Platinum that’ll set you back $1,980.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0061-012/3204-1-eng-GB/f0061-012.jpg","portrait":false,"width":"593","height":"436","legacy_id":"431"},{"id":"zinio_100340926_image_2_1439381007.5019","name":"f0060-01","source":"","caption":"<p><b>Here’s what</b> 128GB of DDR4 looks like.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0060-012/3211-1-eng-GB/f0060-012.jpg","portrait":true,"width":"732","height":"567","legacy_id":"432"},{"id":"zinio_100340926_image_2_1439381007.5019","name":"f0060-01","source":"","caption":"<p><b>Here’s what</b> 128GB of DDR4 looks like.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0060-012/3211-1-eng-GB/f0060-012.jpg","portrait":false,"width":"732","height":"567","legacy_id":"432"},{"id":"zinio_100340926_image_1_1439381008.0957","name":"f0059-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0059-012/3218-1-eng-GB/f0059-012.jpg","portrait":true,"width":"878","height":"497","legacy_id":"433"},{"id":"zinio_100340926_image_1_1439381008.0957","name":"f0059-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0059-012/3218-1-eng-GB/f0059-012.jpg","portrait":false,"width":"878","height":"497","legacy_id":"433"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"11","folio_number":"58","folio_numbers":"58,59,60,61,62,63,64","pdf_page_index":"58","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0058-012/3225-1-eng-GB/f0058-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"427","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381010.1025","title":"Lenovo Yoga Tablet 2 Anypen (8-inch): Yes, you can write on it with a fork","sub_title":"","author":[{"id":"0","name":"JON L. JACOBI","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"Lenovo Yoga Tablet 2 Anypen (8-inch)","intro":"","body":"<p class=\"byline\"><b>BY JON L. JACOBI</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0065-012/3275-1-eng-GB/f0065-012.jpg\" width=\"759\" height=\"776\"  style=\"border: 0px  ;\" alt=\"f0065-01\" title=\"f0065-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>W</b>hen last I communed with a Windows-powered Lenovo Yoga Tablet 2 (the 10-inch version), the event was soured by the worst auxiliary keyboard I’ve ever experienced. Thankfully, Lenovo didn’t see fit to saddle the Windows version of the smaller $300, 8-inch Yoga Tablet 2 Anypen (<a href=\"http://go.pcworld.com/yogatablet2anypen\" target=\"_self\">go.pcworld.com/yogatablet2anypen</a>) with something similarly irritating. The Yoga Anypen is a neat little tablet with an innovative design and versatile digitizer, though not necessarily a platform for serious business use.</p>\n<h3><b>What ‘Anypen’ means</b></h3><p>The headline feature of the Yoga Tablet 2 Anypen is its advanced digitizer. You can use a pencil, ballpoint pen, or just about anything with a metal tip 1mm or larger. Most digitizers require a capacitive stylus with at least a 5mm tip. You might want to avoid X-Acto knives, but other than that you’re good to go. You may, of course, also use your fingers.</p>\n<p>Another unique aspect of the Yoga Tablet 2 design is the cylinder running along one edge that allows for a far larger battery than a normal, flat tablet can accommodate. The battery tube also allows a grip that uses all your fingers, yet doesn’t place your thumb near the display. Many is the time I’ve accidentally flipped pages on an iPad mini.</p>\n<p>The Yoga Tablet 2 (both sizes) has a distinctive kickstand that jackets the battery tube. It clicks into place at about 42-, 85-, and 180-degree angles, but you can manage angles in between due to the large amount of friction. Even more unique is the hole in the kickstand for hanging the Yoga Tablet 2 on a wall, for storage or an ad-hoc cinematic experience.</p>\n<p>Beyond that, the Yoga Tablet 2 Anypen (with Windows) is, well, a smallish Windows tablet running Windows 8.1. Its outstanding feature in that regard is the free year of Office 365.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0066-012/3268-1-eng-GB/f0066-012.jpg\" width=\"594\" height=\"424\"  style=\"border: 0px  ;\" alt=\"f0066-01\" title=\"f0066-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The cylinder</b> at its base lets you grip the tablet and also lets Lenovo put in a massive 6,400mAh battery.</p>\n</figcaption>\n    \n    \n    \n    </div><p>Hardware-wise, you’re talking a Bay Trail Atom Z3745 CPU, 2GB of DDR3/1066 system memory, an 8-inch 1,920 x 1,200 touchscreen display, and a 32GB eMMC SSD—generally nice specs, but not a lot of disk space for running Windows. Indeed, with only 19.7GB of free disk space before we installed anything, we were unable to use our 20GB data sets for read/write testing.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0067-012/3261-1-eng-GB/f0067-012.jpg\" width=\"591\" height=\"391\"  style=\"border: 0px  ;\" alt=\"f0067-01\" title=\"f0067-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The Yoga 2’s</b> performance easily eclipses the older Atom used in the S12 Netbook, but the newer Surface 3’s Cherry Trail Atom clearly stays ahead.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>Performance and run time</b></h3><p>In my hands-on, the Yoga Tablet 2 Anypen seemed lively enough, but the numbers are strictly Atom: PC Mark 8 rated the tablet at 1,375 in the work test and 897 in the creative test. 3D Mark didn’t measure playable frame rates until it got to Ice Storm Extreme, a Web graphics game where the Tablet 2 Anypen scored 7,967. While that’s quite nice compared to last-generation Atoms, it’s not Core-like. Overall performance, in fact, is pretty much identical to the 10-inch version’s (<a href=\"http://go.pcworld.com/yogatablet2\" target=\"_self\">go.pcworld.com/yogatablet2</a>). In fact, you could look at the 10-inch Yoga Tablet 2 results from our Surface 3 review (<a href=\"http://go.pcworld.com/surface3review\" target=\"_self\">go.pcworld.com/surface3review</a>) and pretend it’s the 8-inch version and not miss a beat.</p>\n<p>Regardless, there were no frustrating waits thanks to the Samsung MBG4GC SSD, which scored 168MBps reading and 75MBps writing 4MB files under CrystalDiskMark. That’s quite good for an eMMC-based SSD.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0068-012/3254-1-eng-GB/f0068-012.jpg\" width=\"729\" height=\"503\"  style=\"border: 0px  ;\" alt=\"f0068-01\" title=\"f0068-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Forgot</b> your digital stylus? No problem. Use your pen instead with the Yoga Tablet 2 Anypen.</p>\n</figcaption>\n    \n    \n    \n    </div><p>Battery life was 6 hours and 58 minutes, and that’s measuring with PCMark’s battery rundown test, which works uninterrupted. Unless you drink a lot more coffee than I do, you can add a few hours to that figure.</p>\n<h3><b>Multimedia and connectivity</b></h3><p>The Yoga Tablet 2 Anypen rendered 1080p movies quite nicely, and the sound is adequate. There’s plenty of volume, enough to create distortion if you crank it up all the way. The stereo separation is also better than average, due to the placement of the speakers on either end of the battery tube. The microSD card slot on the back can expand storage if you want to keep a decent collection of movies on board.</p>\n<p>The only ports on the Tablet 2 Anypen are the headset jack and the micro-USB port, which can be used for temporary storage as well as charging the unit, or conversely, charging other devices. Having that large battery on board is handy. The Wi-Fi is 802.11 a/b/g/n, and there’s Bluetooth for connecting peripherals. Alas, there’s no WiDi or even MHL support via the microUSB, so with the lack of video ports, you really are stuck with the 8-inch display.</p>\n<p>As with any tablet worthy of the name, there are cameras: an 8-megapixel back-facing one for snapping photos, and a 1.6-megapixel front-facing one for Skyping and the like.</p>\n<h3><b>The 8- or 10-inch dilemma: Size vs. weight</b></h3><p>When it comes to mobile computing of the business kind, I generally recommend larger displays and keyboards. My theory is that usage far exceeds tote time, so go for the best computing experience. However, when it comes to tablets, smaller means lighter (the Anypen weighs a measly 0.94 pounds) and easier to hold.</p>\n<p class=\"pullQuote\">As the Yoga Tablet 2 also comes in Android flavors, though without the Anypen digitizer, the display-size (8- or 10-inch) buying decision is complicated.</p>\n<p>As the Yoga Tablet 2 also comes in Android flavors, though without the Anypen digitizer, the display-size (8- or 10-inch) buying decision is complicated. The 8-inch version is better as a tablet, but should you then be opting for Windows? For real work, the screen items and text are small even when you magnify to 150 percent. I had to skip all the way to 200 percent (a custom setting) before my admittedly bad vision was comfortable using Windows. At that point, the extra pixels are basically wasted.</p>\n<h3><b>Conclusion</b></h3><p>The 8-inch Yoga Tablet 2 Anypen (with Windows) is a nicely realized tablet with long run time that lets you use just about anything as a stylus (I used a fork once). It’s good for tablet tasks, and the occasional light business chore, by all means.</p>\n<p>For extensive business usage, opt for the 10-inch Yoga Tablet 2 but forgo Lenovo’s misbegotten BC800 keyboard. Or, if I’m really going to be honest, buy an 11- to 13-inch laptop.</p>\n","layout":{"landscape":{"id":"am-landscape-18","link":"rr_article_02-l.twig"},"portrait":{"id":"am-portrait-18","link":"rr_article_02.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381012.2042","name":"f0065-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0065-012/3275-1-eng-GB/f0065-012_story_img_size_768x0.jpg","portrait":true,"width":"751","height":"768","legacy_id":"440","is_default":true},{"id":"zinio_100340926_image_0_1439381012.2042","name":"f0065-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0065-012/3275-1-eng-GB/f0065-012_story_img_size_768x0.jpg","portrait":false,"width":"751","height":"768","legacy_id":"440","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_3_1439381010.2814","name":"f0068-01","source":"","caption":"<p><b>Forgot</b> your digital stylus? No problem. Use your pen instead with the Yoga Tablet 2 Anypen.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0068-012/3254-1-eng-GB/f0068-012.jpg","portrait":true,"width":"729","height":"503","legacy_id":"437"},{"id":"zinio_100340926_image_3_1439381010.2814","name":"f0068-01","source":"","caption":"<p><b>Forgot</b> your digital stylus? No problem. Use your pen instead with the Yoga Tablet 2 Anypen.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0068-012/3254-1-eng-GB/f0068-012.jpg","portrait":false,"width":"729","height":"503","legacy_id":"437"},{"id":"zinio_100340926_image_2_1439381010.9576","name":"f0067-01","source":"","caption":"<p><b>The Yoga 2’s</b> performance easily eclipses the older Atom used in the S12 Netbook, but the newer Surface 3’s Cherry Trail Atom clearly stays ahead.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0067-012/3261-1-eng-GB/f0067-012.jpg","portrait":true,"width":"591","height":"391","legacy_id":"438"},{"id":"zinio_100340926_image_2_1439381010.9576","name":"f0067-01","source":"","caption":"<p><b>The Yoga 2’s</b> performance easily eclipses the older Atom used in the S12 Netbook, but the newer Surface 3’s Cherry Trail Atom clearly stays ahead.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0067-012/3261-1-eng-GB/f0067-012.jpg","portrait":false,"width":"591","height":"391","legacy_id":"438"},{"id":"zinio_100340926_image_1_1439381011.5466","name":"f0066-01","source":"","caption":"<p><b>The cylinder</b> at its base lets you grip the tablet and also lets Lenovo put in a massive 6,400mAh battery.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0066-012/3268-1-eng-GB/f0066-012.jpg","portrait":true,"width":"594","height":"424","legacy_id":"439"},{"id":"zinio_100340926_image_1_1439381011.5466","name":"f0066-01","source":"","caption":"<p><b>The cylinder</b> at its base lets you grip the tablet and also lets Lenovo put in a massive 6,400mAh battery.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0066-012/3268-1-eng-GB/f0066-012.jpg","portrait":false,"width":"594","height":"424","legacy_id":"439"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"12","folio_number":"65","folio_numbers":"65,67,68,69","pdf_page_index":"65","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0065-012/3275-1-eng-GB/f0065-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"436","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381013.2071","title":"M-Disc optical media reviewed: Your data, good for a thousand years","sub_title":"","author":[{"id":"0","name":"JON L. JACOBI","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"M-Disc optical media reviewed","intro":"","body":"<p class=\"byline\"><b>BY JON L. JACOBI</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0070-012/3339-1-eng-GB/f0070-012.jpg\" width=\"554\" height=\"715\"  style=\"border: 0px  ;\" alt=\"f0070-01\" title=\"f0070-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>Y</b>ou’re done with optical discs as a means of data and media delivery, or soon will be. But when done right, as it has been with Millenniata’s M-Disc (<a href=\"http://mdisc.com\" target=\"_self\">mdisc.com</a>), optical has a particular advantage—longevity. Hard-disk mechanisms fail, and the data stored on them can be erased by magnetic fields. Tape stretches and is also magnetically vulnerable. NAND won’t last forever, because cells leak and eventually fail. That leaves M-Disc looking pretty good in the media-preservation, aka archiving, role.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0071-012/3332-1-eng-GB/f0071-012.jpg\" width=\"735\" height=\"397\"  style=\"border: 0px  ;\" alt=\"f0071-01\" title=\"f0071-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>This diagram illustrates</b> the difference between dyebased and inorganic recordable optical discs.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>Optical is dead. Long live optical.</b></h3><p>In the enterprise, optical has enjoyed continued success. Companies such as Sony and Panasonic have continued development both because of its longevity and the minimal environmental support it requires. You think your hard drive generates a lot of heat? Try operating thousands of them. AC bills can be rather high.</p>\n<p>The advent of relatively unstable, dye-based CD/DVD recordable and rewritable, as well as the lack of quality standards governing them, caused many users to forget that pressed optical discs are very longlived. CDs from the 80’s and 90’s should still play fine, assuming you haven’t scratched them up. Same deal with DVD and Blu-ray movies, which are manufactured similarly. And, even though few are aware of it, write-once BD-R HTL (High to Low, i.e., reflectivity, as in bright to dark) is rated to last 100 to 150 years. Why? Because the data layer is a nonvolatile substance, as opposed to the light-sensitive organic dye used in CD/DVD-Rx and less expensive BD-R LTH (Low to High, dark to bright).</p>\n<p>M-Disc also uses a non-volatile data layer, but it’s an even better, rock-like one which is said to last ten times longer than BD-R HTL. If you can’t trust media that’s rated for 1,000 years, you’re pickier than I am. One note: Don’t freak out when you see an M-Disc DVD+R. It’s nearly transparent, but there is a data layer present.</p>\n<h3><b>DoD tested</b></h3><p>As to that thousand-year claim, the U.S. Navy will back that up. It tested M-Disc DVD+Rs along with archival-quality DVD+R/RW and DVD-R/RW, subjecting them three times to a 185-degree, 85-percent humidity, fullspectrum light environment for 26.25 hours. Every DVD failed—except the M-Discs, which suffered no noticeable degradation. The Department of Defense hasn’t tested the new M-Disc BD-R, but as the technology is largely the same, the results should be as well. (We’d guess that BD-R HTL would survive as well.)</p>\n<p>The only failure point for the material used in the M-Disc data layer is oxidation, which, according to Millenniata materials scientists, shouldn’t be an issue for about ten millennia. Yikes. The comparative delicacy of the polycarbonate outer layer of the disc is why the media lasts “only” a thousand years.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0072-012/3325-1-eng-GB/f0072-012.jpg\" width=\"169\" height=\"173\"  style=\"border: 0px  ;\" alt=\"f0072-01\" title=\"f0072-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>You should see a</b> logo like this on compatible DVD burners.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>DVD and Blu-ray Compatibility</b></h3><p>I’m not going to live a thousand years, so the only thing I could test was compatibility. Millenniata was nice enough to send me an M-Disc– compatible optical writer, the Samsung/TSST SE-506CB. RSBD, for write testing. I also tried a vintage 2006 Plextor PX-B320SA, but it didn’t recognize the M-Disc BD-R media as legitimate media for writing.</p>\n<p>As BD-R HTL was part of the Blu-ray standard, and M-Disc functions much the same way, any BD burner is physically capable of writing M-Disc BD media. But as my experience with the PX-B320SA proved, if the firmware doesn’t like it, it won’t work.</p>\n<p>The logo on the front of an optical burner is actually only for M-Disc DVDs, and then only for writing, as many non-logo drives will read it just fine. Laser strength must be increased beyond that normally used with CD/DVD R/RW to ablate the data layer in M-Disc DVDs, so compatible firmware must be in place. Older drives could be upgraded for writing, but as there’s little financial incentive, don’t hold your breath.</p>\n<p>The SE-506CB. RSBD burned flawlessly, so I took the discs it created and tried to read them using every drive I could find. M-Disc says its recordable DVDs should be readable in 90 percent of the DVD drives installed, or being sold now. I didn’t hit 90 percent, but even though recognition could be slow, the majority of the drives I tested read M-Disc just fine (see the table on the next page).</p>\n<p>Though your old drive might work fine, if you’re going to commit to optical for the long haul, it might not be a bad idea to grab one of the latest, greatest Blu-ray burners. Make sure it supports triple-layer, 100GB BDXL for less disc swapping.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0073-01/3318-1-eng-GB/f0073-012.jpg\" width=\"649\" height=\"643\"  style=\"border: 0px  ;\" alt=\"f0073-01\" title=\"f0073-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0074-012/3311-1-eng-GB/f0074-012.jpg\" width=\"477\" height=\"300\"  style=\"border: 0px  ;\" alt=\"f0074-01\" title=\"f0074-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><h3><b>Not dirt-cheap and other negatives</b></h3><p>M-Disc released 4.7GB DVD discs, which are suitable for archiving documents and perhaps your most treasured photos, last year. For video or other larger files, the recently released 25GB and 100GB BD-R, as well as the soon-tobe-released (Q3) 50GB BD-R discs should take care of business.</p>\n<p>But M-Discs aren’t cheap. At retail, the DVDs are about $3, the 25GB discs about $5, the upcoming 50GB discs around $10, and the 100GB $20 or so. Just keep in mind that this is not media that you’ll have to roll over every few years, as with CD/DVD R/RW or dyebased BD-R LTH. It’s a one-time deal. At least until the next technological storage shift.</p>\n<p>Because the media is expensive and not as capacious as a hard drive, you’ll have to choose what’s really important and perhaps divvy it up across discs. You may view this either as an opportunity to clean house or as a deal-buster.</p>\n<p>Also, as always, optical is relatively slow: M-Disc BD discs write at a rather pokey 4X/18MBps (6X/27MBps is the BD max), and M-Disc DVD is also 4X, or 5.28MBps. That’s way off the DVD maximum, which is 16X or 21MBps. But it’s a once-in-a-while deal, so just start your backup, minimize it, and go on about your business.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0074-02/3304-1-eng-GB/f0074-022.jpg\" width=\"343\" height=\"396\"  style=\"border: 0px  ;\" alt=\"f0074-02\" title=\"f0074-02\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>M-Disc BD-R</b> three-pack.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>Why not online archiving?</b></h3><p>Online archiving is certainly an option, but even in the age of ubiquitous broadband, online storage is relatively slow, even slower than optical in many cases. And relatively expensive. And unavailable when communications systems are down. You don’t know who has access to the data, and you don’t know how well the data center is backed up.</p>\n<p>Yes, I have a streak of paranoia, but it’s born of experience. There’s nothing quite like knowing there’s a backup in your safe deposit box or at your relatives’ house. Not that you shouldn’t store a copy online as well.</p>\n<p class=\"pullQuote\">There’s nothing quite like knowing there’s a backup in your safe deposit box or at your relatives’ house. Not that you shouldn’t store a copy online as well.</p>\n<p>I’d strayed from optical for all the usual reasons: lack of speed and capacity, expense, bad discs, etc. But I’m back and fully intend to keep my most important data, the stuff that can’t be replaced, archived on M-Disc. BD-R HTL would do, but just in case I do live a thousand years, I’ll use M-Disc.</p>\n","layout":{"landscape":{"id":"am-landscape-19","link":"rr_article_03-l.twig"},"portrait":{"id":"am-portrait-19","link":"rr_article_03.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381016.2391","name":"f0070-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0070-012/3339-1-eng-GB/f0070-012_story_img_size_768x0.jpg","portrait":true,"width":"595","height":"768","legacy_id":"448","is_default":true},{"id":"zinio_100340926_image_0_1439381016.2391","name":"f0070-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0070-012/3339-1-eng-GB/f0070-012_story_img_size_768x0.jpg","portrait":false,"width":"595","height":"768","legacy_id":"448","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_5_1439381013.3493","name":"f0074-02","source":"","caption":"<p><b>M-Disc BD-R</b> three-pack.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0074-02/3304-1-eng-GB/f0074-022.jpg","portrait":true,"width":"343","height":"396","legacy_id":"443"},{"id":"zinio_100340926_image_5_1439381013.3493","name":"f0074-02","source":"","caption":"<p><b>M-Disc BD-R</b> three-pack.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0074-02/3304-1-eng-GB/f0074-022.jpg","portrait":false,"width":"343","height":"396","legacy_id":"443"},{"id":"zinio_100340926_image_4_1439381013.9614","name":"f0074-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0074-012/3311-1-eng-GB/f0074-012.jpg","portrait":true,"width":"477","height":"300","legacy_id":"444"},{"id":"zinio_100340926_image_4_1439381013.9614","name":"f0074-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0074-012/3311-1-eng-GB/f0074-012.jpg","portrait":false,"width":"477","height":"300","legacy_id":"444"},{"id":"zinio_100340926_image_3_1439381014.5422","name":"f0073-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0073-01/3318-1-eng-GB/f0073-012.jpg","portrait":true,"width":"649","height":"643","legacy_id":"445"},{"id":"zinio_100340926_image_3_1439381014.5422","name":"f0073-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0073-01/3318-1-eng-GB/f0073-012.jpg","portrait":false,"width":"649","height":"643","legacy_id":"445"},{"id":"zinio_100340926_image_2_1439381015.1045","name":"f0072-01","source":"","caption":"<p><b>You should see a</b> logo like this on compatible DVD burners.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0072-012/3325-1-eng-GB/f0072-012.jpg","portrait":true,"width":"169","height":"173","legacy_id":"446"},{"id":"zinio_100340926_image_2_1439381015.1045","name":"f0072-01","source":"","caption":"<p><b>You should see a</b> logo like this on compatible DVD burners.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0072-012/3325-1-eng-GB/f0072-012.jpg","portrait":false,"width":"169","height":"173","legacy_id":"446"},{"id":"zinio_100340926_image_1_1439381015.6853","name":"f0071-01","source":"","caption":"<p><b>This diagram illustrates</b> the difference between dyebased and inorganic recordable optical discs.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0071-012/3332-1-eng-GB/f0071-012.jpg","portrait":true,"width":"735","height":"397","legacy_id":"447"},{"id":"zinio_100340926_image_1_1439381015.6853","name":"f0071-01","source":"","caption":"<p><b>This diagram illustrates</b> the difference between dyebased and inorganic recordable optical discs.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0071-012/3332-1-eng-GB/f0071-012.jpg","portrait":false,"width":"735","height":"397","legacy_id":"447"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"13","folio_number":"70","folio_numbers":"70,71,72,73,74,75","pdf_page_index":"70","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0070-012/3339-1-eng-GB/f0070-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"442","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381017.6162","title":"EVGA GeForce GTX 980 Ti Superclocked+ unleashes Maxwell’s true power","sub_title":"","author":[{"id":"0","name":"BRAD CHACOS","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"EVGA GeForce GTX 980 Ti Superclocked+ unleashes Maxwell’s true power","intro":"","body":"<p class=\"byline\"><b>BY BRAD CHACOS</b></p>\n<p><b>I </b>eagerly anticipated<b> </b>reviewing the most powerful single-GPU graphics card to ever grace PCWorld’s test bench—and I wasn’t disappointed. But the card that claimed that title wasn’t the one I expected! While AMD’s new, hotly anticipated Radeon R9 Fury X is a beast in its own right, the title of new heavyweight champion instead lies with EVGA’s $680 GeForce GTX 980 Ti Superclocked+ with ACX 2.0+ (<a href=\"http://go.pcworld.com/evgagtx980ti\" target=\"_self\">go.pcworld.com/evgagtx980ti</a>), a custom-cooled, overclocked variant of Nvidia’s ferocious GTX 980 Ti.</p>\n<p>EVGA sent me this card out of the blue on the same day I received the Fury X—a coincidence, I’m sure. But the GTX 980 Ti Superclocked+ doesn’t just triumph over AMD’s new flagship, it outpunches Nvidia’s own $1,000 Titan X in raw firepower.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0076-012/3431-1-eng-GB/f0076-012.jpg\" width=\"723\" height=\"421\"  style=\"border: 0px  ;\" alt=\"f0076-01\" title=\"f0076-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0077-01/3424-1-eng-GB/f0077-012.jpg\" width=\"592\" height=\"377\"  style=\"border: 0px  ;\" alt=\"f0077-01\" title=\"f0077-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Details about the</b> EVGA GeForce GTX 980 Ti Superclocked+’s ACX 2.0+ cooling solution.</p>\n</figcaption>\n    \n    \n    \n    </div><p>What’s more, even though AMD’s dual-GPU Radeon R9 295x2 still manages to outrun EVGA’s beast, the GTX 980 Ti Superclocked+ illuminates a key advantage the 980 Ti family holds over all other 4K-capable graphics cards.</p>\n<p>Let’s dig in!</p>\n<h3><b>EVGA GeForce GTX 980 Ti Superclocked+ under the hood</b></h3><p>For the most part, EVGA’s card rocks the same basic tech specs as the reference GTX 980 Ti, which we covered in full in our initial review of Nvidia’s gaming Goliath (<a href=\"http://go.pcworld.com/nvidiagtx980rev\" target=\"_self\">go.pcworld.com/nvidiagtx980rev</a>). You find the same 2,048 CUDA cores, the same 6GB of GDDR5 memory with a 7Gbps clock speed and a 384-bit bus, the same port selection, et cetera. You can find more details about Nvidia’s GM200 chip itself in our earlier review. The chart on the next page has the basic technical information, specifically for the EVGA GTX 980 Ti Superclocked+ (henceforth to be referred to as the GTX 980 Ti SC+).</p>\n<p>So what makes the EVGA GTX 980 Ti SC+ so special? The (full) name gives it all away. The card ditches the GTX 980 Ti’s reference cooling in favor of EVGA’s respected ACX 2.0+ cooling system, which has made an appearance on several Nvidia GPUs at this point. Rather than talking about its dual fans, custom heat pipe, MOSFET cooling pipe, and quiet operation yet again, we provide an EVGA-supplied diagram showing it all on the previous page. You’ll see the results in our benchmarking section.</p>\n<p class=\"pullQuote\">Getting that kind of overclock out of the box, with full 3-year warranty support, is no joke.</p>\n<p>The other tell-tale in the name is <i>Superclocked+</i>. The drastic cooling enhancements provided by ACX 2.0+ let EVGA positively crank the core clock speed on this bad boy, a tweak that helps it beat both the Fury X and the Titan X out of the box. While the stock GTX 980 Ti is clocked at 1,000MHz base clock/1,075MHz boost clock, EVGA’s managed to coax those numbers up to 1,102MHz base/1,190MHz boost in the GTX 980 Ti SC+—a sizeable jump.</p>\n\n<div>\n<table bgcolor=\"#eeeeee\">\n<tr>\n    <td>\n    <h3><b>Specifications</b></h3><p>• Base Clock: 1102 MHz</p>\n<p>• Boost Clock: 1190 Mhz</p>\n<p>• Memory Clock: 7010 Mhz Effective</p>\n<p>• CUDA Cores: 2816</p>\n<p>• Bus Type: PCI:E 3.0</p>\n<p>• Memory Detail: 6144MB GDDR5</p>\n<p>• Memory Bit Width: 384 Bit</p>\n<p>• Memory Speed: 0.28 ns</p>\n<p>• Memory Bandwidth: 336.5 BG/s</p>\n<h3><b>Dimensions</b></h3><p>• Height: 4.376in – 111.5mm</p>\n<p>• Length: 10.5 – 266.7mm</p>\n<p>• Width: Dual Slot</p>\n<p><b>DVI-I</b></p>\n<p><b>DISPLAY PORT</b></p>\n<p><b>DISPLAY PORT</b></p>\n<p><b>DISPLAY PORT</b></p>\n<p><b>HDMI</b></p>\n\n    </td>\n</tr>\n</table>\n</div><p>Getting that kind of overclock out of the box, with full 3-year warranty support, is no joke.</p>\n<p>If you want to push things even further—or boost the memory speed, which is left untouched from stock on the GTX 980 Ti SC+—you can turn to EVGA’s stellar PrecisionX overclocking software, which is available as a free download on EVGA’s website (<a href=\"http://go.pcworld.com/precisionx\" target=\"_self\">go.pcworld.com/precisionx</a>) or via Steam (<a href=\"http://go.pcworld.com/precisionxsteam\" target=\"_self\">go.pcworld.com/precisionxsteam</a>). It’s a great solution, blending user-friendliness with the fine-tuning features power users demand. Need a primer? PCWorld’s overclocking guide (<a href=\"http://go.pcworld.com/overclockgc\" target=\"_self\">go.pcworld.com/overclockgc</a>) refers to MSI’s competing Afterburner tool, but the same basic overclocking principles apply with PrecisionX.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0079-012/3417-1-eng-GB/f0079-012.jpg\" width=\"613\" height=\"281\"  style=\"border: 0px  ;\" alt=\"f0079-01\" title=\"f0079-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The EVGA</b> GeForce GTX 980 Ti Superclocked+’ s backplate.</p>\n</figcaption>\n    \n    \n    \n    </div><p>One final design tidbit: EVGA’s GTX 980 Ti SCi+ comes with an eyecatching custom backplate installed. Unlike the vanilla GTX 980, the reference GTX 980 Ti eschewed a backplate, ostensibly to facilitate better airflow in multi-GPU setups, but I’m a sucker for a nice backplate. Who wants to stare at exposed circuit boards?</p>\n<h3><b>EVGA GeForce GTX 980 Ti Superclocked+ benchmarks</b></h3><p>With that out of the way, let’s get to the fun part.</p>\n<p>As always, we reviewed the GTX 980 Ti on PCWorld’s graphics testing system. You can see how we built the system here, but here are the basics:</p>\n<p>• Intel’s Core i7-5960X with a Corsair Hydro Series H100i closedloop water cooler, to eliminate any potential for CPU bottlenecks affecting graphical benchmarks</p>\n<p>• An Asus X99 Deluxe motherboard</p>\n<p>• Corsair’s Vengeance LPX DDR4 memory, Obsidian 750D full tower case, and 1200-watt AX1200i power supply</p>\n<p>• A 480GB Intel 730 series SSD</p>\n<p>• Windows 8.1 Pro</p>\n<p>I’ve already spoiled the results by calling this the fastest graphics card we’ve ever tested, but if you’re looking to game at high or ultra graphics settings at 4K resolution, the same caveats mentioned in our Fury X, Titan X, and reference GTX 980 Ti still apply. While all of these cards are fully capable of handling 4K gameplay by their lonesome, frame rates can still hover between 30 to 60 fps in some titles, depending on the settings you’re using.</p>\n<p>A G-Sync monitor, which forces your graphics card and display to synchronize frame rates, greatly improves the experience when gaming at 4K by smoothing everything out and essentially killing both screen tearing and stuttering. Simply put, G-Sync (and AMD’s competing FreeSync displays, designed for Radeon cards) are wonderful. If you can afford to pick up a G-Sync monitor to pair with EVGA’s GTX 980 Ti SC+, it’s highly recommended.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0080-01/3410-1-eng-GB/f0080-012.jpg\" width=\"592\" height=\"494\"  style=\"border: 0px  ;\" alt=\"f0080-01\" title=\"f0080-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0081-012/3403-1-eng-GB/f0081-012.jpg\" width=\"591\" height=\"479\"  style=\"border: 0px  ;\" alt=\"f0081-01\" title=\"f0081-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>The GTX 980 Ti’s cranked clock speeds help it shine in every test I ran. First up: <i>Middle-earth: Shadow of Mordor</i>. The game itself is great, but more importantly, it comes with an in-game benchmark and an optional Ultra HD Textures pack that hammers the memory of even the most capable cards on the market today. It’s tested using the game’s Medium and High presets, then shifting to the Ultra preset and then cranking every graphics option to its highest possible setting—which even the Ultra preset doesn’t actually do. (Note: No matter which drivers I’m using, I just can’t coax <i>Shadow of Mordor</i> into playing nice with AMD’s dual-GPU Radeon R9 295x2.)</p>\n<p>The long-awaited <i>Grand Theft Auto V</i> is finally available on PCs, and with all the bells and whistles on, it can be a bear. We tested it by enabling all the advanced video options, then shifting all the graphics settings and sliders to their highest settings. I tested it with 4x MSAA and 4x MSAA reflections enabled to push the active memory use over 4GB, as well as with the MSAA options disabled to bring it just under 4GB—primarily to test the Fury X’s 4GB of cutting-edge highbandwidth memory at 4K resolution. To see complete benchmark results from all of our tests, go to <a href=\"http://go.pcworld.com/evgabench\" target=\"_self\">go.pcworld.com/evgabench</a>. <i>Sleeping Dogs: Definitive Edition</i> is a recent remake of a wonderful older game, but don’t let that fool you: It can make even the most powerful graphics cards in the land sweat when you enable all its graphics options. Only the Radeon R9 295x2 hits 30 fps at 4K resolution, and although results at 2560 x 1600 resolution aren’t shown here, not even that card can hit 60fps at that lower resolution on extreme graphics settings.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0082-012/3396-1-eng-GB/f0082-012.jpg\" width=\"591\" height=\"566\"  style=\"border: 0px  ;\" alt=\"f0082-01\" title=\"f0082-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><i>Alien Isolation</i> is the best xenomorph experience since the original Alien movie, and when it comes to graphics, it scales well across all hardware.</p>\n<p><i>Dragon Age: Inquisition</i> is drop-dead gorgeous and one of the best PC games of 2014. Despite being heavily promoted by AMD at its launch, the game performs better on Nvidia hardware.</p>\n<p>We tested <i>Metro Last Light Redux</i> with SSAA and Advanced PhysX disabled. SSAA cuts frame rates in half for negligible visual gain.</p>\n<p><i>Bioshock Infinite</i> is getting a bit long in the tooth, but it uses the popular <i>Unreal Engine 3</i> and both AMD and Nvidia have had plenty of time to optimize their drivers for the game by this point.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0083-012/3389-1-eng-GB/f0083-012.jpg\" width=\"591\" height=\"788\"  style=\"border: 0px  ;\" alt=\"f0083-01\" title=\"f0083-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>Next up: The 3DMark Fire Strike and Unigine Valley synthetic benchmark tests. Fire Strike Ultra is a more demanding variant of the base Fire Strike benchmark, built specifically to test 4K gaming capabilities.</p>\n<p>Power usage and thermal testing is conducted by running the grueling Furmark tool for 15 minutes. Thermals are measured at the end of the run, using both Furmark’s built-in temperature tool as well as SpeedFan. Power usage is measured on a whole-system basis, rather than the individual cards themselves, by plugging the PC into a Watts Up meter.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0084-012/3382-1-eng-GB/f0084-012.jpg\" width=\"591\" height=\"650\"  style=\"border: 0px  ;\" alt=\"f0084-01\" title=\"f0084-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0085-012/3375-1-eng-GB/f0085-012.jpg\" width=\"591\" height=\"672\"  style=\"border: 0px  ;\" alt=\"f0085-01\" title=\"f0085-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>The GTX 980 Ti SC+’s custom cooling solution helps it shave a full 9 degrees Celsius off the power use at load when compared to the reference GTX 980 Ti. And while it doesn’t show in the raw benchmarks—I don’t have a decibel meter on hand—EVGA’s card runs pretty damned quiet, even when you’re hammering it with a demanding game. (Though obviously not as cool or quiet as AMD’s Fury X and R9 295x2, each of which uses an integrated closed-loop water cooler.)</p>\n<h3><b>Bottom line</b></h3><p>The EVGA GeForce GTX 980 Ti Superclocked+’s outstanding performance comes as no surprise. The reference GTX 980 Ti was already a beast in every sense of the word, so slapping a slick custom cooler on it and cranking the clock speeds was guaranteed to turn the GTX 980 Ti SC+ into a true barn-burner. EVGA’s excellent build quality and design thoughtfulness is just icing on the delicious cake.</p>\n<p>You could push frame rates to even more blistering levels with esoteric liquid-cooling solutions that allow for higher overclocks— witness EVGA’s own GeForce GTX 980 Ti Hydro Copper and GeForce GTX 980 Ti Hybrid, with their insane 1,228MHz boost clock speeds out of the box, for evidence of that. Meanwhile, some other cards, like MSI’s GTX 980 Ti Gaming 6G, manage to push the boost clock speeds beyond that. Those cards would no doubt hit frame rates even higher than the ones the GTX 980 Ti SC+ achieved here.</p>\n<p>But as it stands, the EVGA GeForce GTX 980 Ti Superclocked+ is hands-down the fastest single-GPU graphics card we’ve ever tested, barely coming in second to only the formidable dual-GPU Radeon R9 295x2 (and its integrated closed-loop water cooler) in our testing. It’s a thrilling example of the kind of firepower that a custom-cooled, sped-up GTX 980 Ti can bring to the table—something that the flagship Titan X and Fury X can’t offer, with Nvidia and AMD locking those cards down to reference designs only.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0086-01/3368-1-eng-GB/f0086-012.jpg\" width=\"356\" height=\"360\"  style=\"border: 0px  ;\" alt=\"f0086-01\" title=\"f0086-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><h3><b>Hail to the new king, baby.</b></h3><p>Finally, the sterling performance of the $680 GTX 980 Ti SC+ is yet more proof that gamers should pass on the beastly $1,000 Titan X, even with the latter’s 12GB of RAM. If you picked up one of those Titan X’s when it was the clear lord of the land a few scant months ago…well, there’s a reason that graphics card lust is the cruelest obsession.</p>\n","layout":{"landscape":{"id":"am-landscape-23","link":"rr_secondary_03-l.twig"},"portrait":{"id":"am-portrait-23","link":"rr_secondary_03.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381022.9681","name":"f0076-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0076-012/3431-1-eng-GB/f0076-012_story_img_size_768x0.jpg","portrait":true,"width":"1319","height":"768","legacy_id":"460","is_default":true},{"id":"zinio_100340926_image_0_1439381022.9681","name":"f0076-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0076-012/3431-1-eng-GB/f0076-012_story_img_size_768x0.jpg","portrait":false,"width":"1319","height":"768","legacy_id":"460","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_9_1439381017.8301","name":"f0086-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0086-01/3368-1-eng-GB/f0086-012.jpg","portrait":true,"width":"356","height":"360","legacy_id":"451"},{"id":"zinio_100340926_image_9_1439381017.8301","name":"f0086-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0086-01/3368-1-eng-GB/f0086-012.jpg","portrait":false,"width":"356","height":"360","legacy_id":"451"},{"id":"zinio_100340926_image_8_1439381018.4062","name":"f0085-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0085-012/3375-1-eng-GB/f0085-012.jpg","portrait":true,"width":"591","height":"672","legacy_id":"452"},{"id":"zinio_100340926_image_8_1439381018.4062","name":"f0085-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0085-012/3375-1-eng-GB/f0085-012.jpg","portrait":false,"width":"591","height":"672","legacy_id":"452"},{"id":"zinio_100340926_image_7_1439381019.0306","name":"f0084-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0084-012/3382-1-eng-GB/f0084-012.jpg","portrait":true,"width":"591","height":"650","legacy_id":"453"},{"id":"zinio_100340926_image_7_1439381019.0306","name":"f0084-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0084-012/3382-1-eng-GB/f0084-012.jpg","portrait":false,"width":"591","height":"650","legacy_id":"453"},{"id":"zinio_100340926_image_6_1439381019.6167","name":"f0083-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0083-012/3389-1-eng-GB/f0083-012.jpg","portrait":true,"width":"591","height":"788","legacy_id":"454"},{"id":"zinio_100340926_image_6_1439381019.6167","name":"f0083-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0083-012/3389-1-eng-GB/f0083-012.jpg","portrait":false,"width":"591","height":"788","legacy_id":"454"},{"id":"zinio_100340926_image_5_1439381020.1944","name":"f0082-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0082-012/3396-1-eng-GB/f0082-012.jpg","portrait":true,"width":"591","height":"566","legacy_id":"455"},{"id":"zinio_100340926_image_5_1439381020.1944","name":"f0082-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0082-012/3396-1-eng-GB/f0082-012.jpg","portrait":false,"width":"591","height":"566","legacy_id":"455"},{"id":"zinio_100340926_image_4_1439381020.7561","name":"f0081-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0081-012/3403-1-eng-GB/f0081-012.jpg","portrait":true,"width":"591","height":"479","legacy_id":"456"},{"id":"zinio_100340926_image_4_1439381020.7561","name":"f0081-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0081-012/3403-1-eng-GB/f0081-012.jpg","portrait":false,"width":"591","height":"479","legacy_id":"456"},{"id":"zinio_100340926_image_3_1439381021.3067","name":"f0080-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0080-01/3410-1-eng-GB/f0080-012.jpg","portrait":true,"width":"592","height":"494","legacy_id":"457"},{"id":"zinio_100340926_image_3_1439381021.3067","name":"f0080-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0080-01/3410-1-eng-GB/f0080-012.jpg","portrait":false,"width":"592","height":"494","legacy_id":"457"},{"id":"zinio_100340926_image_2_1439381021.908","name":"f0079-01","source":"","caption":"<p><b>The EVGA</b> GeForce GTX 980 Ti Superclocked+’ s backplate.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0079-012/3417-1-eng-GB/f0079-012.jpg","portrait":true,"width":"613","height":"281","legacy_id":"458"},{"id":"zinio_100340926_image_2_1439381021.908","name":"f0079-01","source":"","caption":"<p><b>The EVGA</b> GeForce GTX 980 Ti Superclocked+’ s backplate.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0079-012/3417-1-eng-GB/f0079-012.jpg","portrait":false,"width":"613","height":"281","legacy_id":"458"},{"id":"zinio_100340926_image_1_1439381022.396","name":"f0077-01","source":"","caption":"<p><b>Details about the</b> EVGA GeForce GTX 980 Ti Superclocked+’s ACX 2.0+ cooling solution.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0077-01/3424-1-eng-GB/f0077-012.jpg","portrait":true,"width":"592","height":"377","legacy_id":"459"},{"id":"zinio_100340926_image_1_1439381022.396","name":"f0077-01","source":"","caption":"<p><b>Details about the</b> EVGA GeForce GTX 980 Ti Superclocked+’s ACX 2.0+ cooling solution.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0077-01/3424-1-eng-GB/f0077-012.jpg","portrait":false,"width":"592","height":"377","legacy_id":"459"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"14","folio_number":"76","folio_numbers":"76,77,78,79,80,81,82,83,84,85,86","pdf_page_index":"76","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0076-012/3431-1-eng-GB/f0076-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"450","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381024.2957","title":"Radeon R9 Fury X graphics card: AMD’s long-awaited 4K powerhouse","sub_title":"","author":[{"id":"0","name":"BRAD CHACOS","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"Radeon R9 Fury X graphics card: AMD’s long-awaited 4K powerhouse","intro":"","body":"<p class=\"byline\"><b>BY BRAD CHACOS</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0088-012/3544-1-eng-GB/f0088-012.jpg\" width=\"788\" height=\"523\"  style=\"border: 0px  ;\" alt=\"f0088-01\" title=\"f0088-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>A</b>MD’S Radeon R9 Fury X kicks ass.</p>\n<p>It’s important to note that right up front, because AMD’s graphics division has had a rough year. The company’s been forced to watch Nvidia release not one, not two, but five new GeForce graphics cards— the entire GTX 900-series line—since the Radeon R9 285 launched last September. What’s more, those GeForce cards delivered so much performance and sipped so little power that all AMD could do in response was steeply slash the prices of its Radeon R200-series graphics cards to stay competitive. And AMD’s “new” Radeon R300-series cards are basically just tweaked versions of the R200-series GPUs with more memory.</p>\n<p>Through it all, the promise of the water-cooled Radeon R9 Fury X (<a href=\"http://go.pcworld.com/fury\" target=\"_self\">go.pcworld.com/fury</a>) glimmered as the light at the end of the tunnel, first through unofficial leaks and then through official reveals. It’ll have cutting-edge high-bandwidth memory! It’ll have a new Fiji graphics processor with an insane 4,096 stream processors! It’ll have an integrated closed-loop water cooler! It’ll play 4K games and go toe-to-toe with Nvidia’s beastly Titan X and GTX 980 Ti!</p>\n<p>And it’s all true. Every last bit of it. The Radeon R9 Fury X kicks ass.</p>\n<p>It’s not quite the walk-off home run that Team Red enthusiasts were hoping for, however—and AMD’s claim that the Fury X is “an overclocker’s dream” definitely does not pass muster.</p>\n<p>Let’s dig in.</p>\n<h3><b>AMD’s Radeon R9 Fury X under the hood</b></h3><p>There isn’t much mystery to the Fury X’s technical specifications at this point. AMD long ago provided a deep-dive into the card’s HBM implementation (<a href=\"http://go.pcworld.com/hbm\" target=\"_self\">go.pcworld.com/hbm</a>) and described the Fury X’s technical and design details (<a href=\"http://pcworld.com/furyxtechspecs\" target=\"_self\">pcworld.com/furyxtechspecs</a>) with loving exactness. We’ll cover the high points here, but check out our previous coverage if you’re looking for more details.</p>\n<p>The most notable technical aspect of the Fury X is its use of highbandwidth memory, making it the first graphics card to adopt HBM. AMD says it’s been developing the technology for seven years, and Nvidia’s not expected to embrace similar technology until 2016 at the earliest, when its Pascal GPUs launch.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0089-012/3537-1-eng-GB/f0089-012.jpg\" width=\"736\" height=\"319\"  style=\"border: 0px  ;\" alt=\"f0089-01\" title=\"f0089-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>A diagram</b> of AMD’s HBM implementation.</p>\n</figcaption>\n    \n    \n    \n    </div><p>HBM stacks DRAM dies one atop the other, then connects everything with the GPU using “through-silicon vias” and “μbumps” (microbumps). The stacking lets 1GB of HBM consume a whopping 94 percent less on-board surface area than 1GB of standard GDDR5 memory, which enabled AMD to make the Fury X a full 30 percent shorter than the Radeon R9 290X.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0090-012/3530-1-eng-GB/f0090-012.jpg\" width=\"590\" height=\"317\"  style=\"border: 0px  ;\" alt=\"f0090-01\" title=\"f0090-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>HBM space</b> savings over GDDR5.</p>\n</figcaption>\n    \n    \n    \n    </div><p>While GDDR5 memory rocks high clock speeds (up to 7Gbps) and uses a smaller interface to connect the GPU—384-bit, or 512-bit in high-end graphics cards—HBM takes the opposite approach. The Fury X’s memory is clocked at a mere 1Gbps, but travels over a ridonkulously wide 4,096-bit bus to deliver effective memory bandwidth of 512GBps, compared to the GTX 980 Ti’s 336.5GBps. All that memory bandwidth makes for great 4K gaming, though it doesn’t give the Fury X a clear edge over the 980 Ti when it comes to games, as we’ll see later</p>\n<p>Technological limitations capped this first-gen HBM at just 4GB of capacity. While AMD CTO Joe Macri told us in May that’s all developers really need for now, it definitely proved to be a problem in our testing when playing games that gobbled up more than 4GB of RAM—<i>Grand Theft Auto V</i>, specifically. Gaming at 4K resolution can eat up memory fast once you’ve enabled any sort of anti-aliasing.</p>\n<p>Moving past memory, AMD’s new Fiji GPU is nothing short of a beast, packed to the gills with a whopping 4,096 stream processors— compared to the R9 290X’s 2,816—and 8.9 billion transistors. It’s clocked at 1,050MHz, promises 8.6 teraflops of compute performance, and draws 275 watts of power through two 8-pin power connectors that can draw up to 375W.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0091-012/3523-1-eng-GB/f0091-012.jpg\" width=\"420\" height=\"285\"  style=\"border: 0px  ;\" alt=\"f0091-01\" title=\"f0091-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>AMD’s</b> Fiji GPU.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>The Radeon R9 Fury X over the hood</b></h3><p>AMD spared no expense on the physical design of the Fury X, either. The 7.5-inch card is built from multiple pieces of die-cast aluminum, then finished with a black nickel gloss on the exoskeleton and softtouch black everywhere else. Everything’s covered, even the sides and back of the card. There’s not even an exhaust grille on the I/O plate, which rocks a trio of full-sized DisplayPorts and an HDMI port that’s sadly limited to the HDMI 1.4a specification. The decision not to go with HDMI 2.0 limits 4K video output to 30Hz through the HDMI port, so gamers will want to stick to using the DisplayPorts.</p>\n<p>You’ll find an illuminated red Radeon logo on the outer edge and face of the card, along with a new “GPU Tach” (as in “tachometer”) feature that places 8 small red LEDs above the power connections. The harder you push the card, the more LEDs light up. It’s super-dumb but honestly, it thrilled me to no end watching those little LEDs flare to life when booting up a game. There’s also a small green LED next to those that illuminates when AMD’s ZeroCore technology puts the Fury X to sleep. This thing screams “premium.”</p>\n<p>That extends to the Fury X’s cooling system. Rather than going with a typical air-cooling solution, with a fan or blower, the Fury X utilizes an integrated closedloop liquid cooler that’s basically a more refined version of the beastly Radeon R9 295x2’s water-cooling setup. It’s a slick custom design built in conjunction with Cooler Master, rocking a 120mm fan from Nidec on the radiator. AMD says the cooler itself is rated for up to 500W of thermal capacity.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0092-012/3516-1-eng-GB/f0092-012.jpg\" width=\"434\" height=\"233\"  style=\"border: 0px  ;\" alt=\"f0092-01\" title=\"f0092-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>See the</b> GPU Tach LEDs just above the two 8-pin power connectors?</p>\n</figcaption>\n    \n    \n    \n    </div><p>Deploying water-cooling indeed keeps the Fury X running nice and cool. Despite AMD’s claim that the fan stays more than 10 decibels quieter than the Titan X’s air-cooled blower, however, I was surprised by just how much noise it puts out. Subjectively—as I don’t have a decibel meter on hand—the Fury X’s radiator fan creates more sound than the fan on Nvidia’s reference GTX 980 Ti and AMD’s own R9 295x2, though I still wouldn’t call it loud.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0092-02/3509-1-eng-GB/f0092-022.jpg\" width=\"419\" height=\"481\"  style=\"border: 0px  ;\" alt=\"f0092-02\" title=\"f0092-02\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The AMD</b> Radeon R9 Fury X’s technical specifications.</p>\n</figcaption>\n    \n    \n    \n    </div><p>The braided cables connecting the radiator to the card itself are a nice touch and far more aesthetically appealing than the R9 295x2’s plastic tubes. Be mindful of where you place the discrete radiator/fan combo, however: At 2.5 inches of total width (the same as the R9 295x2’s), they jut far enough into the case of PCWorld’s GPU testing machine (<a href=\"http://go.pcworld.com/diygamingpc\" target=\"_self\">go.pcworld.com/diygamingpc</a>) to bang against our CPU’s closed-loop liquid cooling.</p>\n<p>Final design note: You won’t be able to buy aftermarket variants of the Fury X with custom cooling or hefty overclocks applied by add-in board vendors like Asus or Sapphire. AMD says the Fury X is a reference design only, though the air-cooled Radeon R9 Fury has vendorcustomized designs available.</p>\n<h3><b>The elephant in the room</b></h3><p>Normally, this is where I’d leap into gaming benchmarks, but I wanted to talk about a more advanced issue first: overclocking.</p>\n<p>With power pins capable of sucking down 100W of additional energy, a liquid-cooling solution rated for up to 500W of thermal capacity, and a redesigned AMD PowerTune/OverDrive that gives you more control over fine-tuning your card’s capabilities, the Radeon R9 Fury X seems tailor-made for hefty overclocking. Heck, AMD even touted the card’s overclockability (that’s a word, right?) at its E3 unveiling. “You’ll be able to overclock this thing like no tomorrow,” AMD CTO Joe Macri said. “This is an overclocker’s dream.”</p>\n<p>That’s… well, that’s just not true, at least for the review sample I was given.</p>\n<p>I was only able to push my Fury X from its 1,050MHz stock clock up to 1100MHz, a very modest bump that added a mere 1 to 2 frames per second of performance in gaming benchmarks. You can’t touch the HBM’s memory clock—AMD locked it down. And any time I tried upping the Fury X’s power limit in AMD’s PowerTune utility, even by 1 percent, instability instantly ensued.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0093-012/3502-1-eng-GB/f0093-012.jpg\" width=\"410\" height=\"343\"  style=\"border: 0px  ;\" alt=\"f0093-01\" title=\"f0093-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>AMD Radeon</b> Fury X with cooler.</p>\n</figcaption>\n    \n    \n    \n    </div><p>An AMD representative told me that “We had a very limited number of OC boards.” When I asked whether there will be different variants of the Fury X, given this “OC board” talk, I was told that there will only be one SKU, and it’s the usual “silicon lottery” when it comes to your GPU’s overclocking capabilities. (Overclocking capabilities vary from individual GPU to individual GPU; another Fury X could have much more headroom than ours, for example.)</p>\n<p>All that said, we’ve heard through the grapevine that we’re not the only ones experiencing disappointing overclocks with the Fury X, either. So if you’re considering picking up a Fury X, peruse the following gaming benchmarks knowing that you may not be able to eke out additional performance via overclocking.</p>\n<h3><b>AMD Radeon R9 Fury X gaming benchmarks</b></h3><p>Enough preamble! Let’s dive into the nitty-gritty.</p>\n<p>As with all of our graphics card reviews, I benchmarked the Radeon R9 Fury X on PCWorld’s GPU testing system, which contains:</p>\n<p>&gt; Intel’s Core i7-5960X with a Corsair Hydro Series H100i closed-loop water cooler, to eliminate any potential for CPU bottlenecks affecting graphical benchmarks</p>\n<p>&gt; An Asus X99 Deluxe motherboard</p>\n<p>&gt; Corsair’s Vengeance LPX DDR4 memory, Obsidian 750D full tower case, and 1200-watt AX1200i power supply</p>\n<p>&gt; A 480GB Intel 730 series SSD</p>\n<p>&gt; Windows 8.1 Pro</p>\n<p>As far as the games go, we used the in-game benchmarks provided with each, utilizing the stock graphics settings mentioned unless otherwise noted. We focused on 4K gaming results for this review.</p>\n<p>I’ve compared the Fury X against Nvidia’s reference GeForce 980 Ti, GeForce 980, and the $1,000 Titan X, as well as AMD’s older Radeon R9 290X and the Radeon R9 295x2, which packs two of the Hawaii GPUs found in the R9 290X. I’ve also included benchmarks from a card that we don’t yet have a formal review for: EVGA’s $680 GeForce GTX 980 Ti Superclocked+ (aka the GTX 980 Ti SC+), an aftermarket version of the GTX 980 Ti that sports EVGA’s popular ACX 2.0+ dual-fan cooling system.</p>\n<p>EVGA sent me the GTX 980 Ti SC+ on the same day AMD passed me the Fury X—pure coincidence, I’m sure.</p>\n<p>Let’s kick things off with <i>Middle-earth: Shadow of Mordor</i>. This nifty little game gobbled down tons of industry awards and, more importantly for our purpose, offers an optional Ultra HD textures pack that is only recommended for cards with 6GB or more of on-board memory. That doesn’t hinder the Fury X’s ability to come out swinging with slightly higher frame rates than the reference GeForce GTX 980 Ti—no small feat, especially when the game opens with a splash page championing Nvidia technology.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0095-012/3495-1-eng-GB/f0095-012.jpg\" width=\"591\" height=\"806\"  style=\"border: 0px  ;\" alt=\"f0095-01\" title=\"f0095-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0096-012/3488-1-eng-GB/f0096-012.jpg\" width=\"510\" height=\"298\"  style=\"border: 0px  ;\" alt=\"f0096-01\" title=\"f0096-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>AMD Radeon</b> Fury X with split view.</p>\n</figcaption>\n    \n    \n    \n    </div><p>The game was tested at Medium and High quality graphics presets, then by using the Ultra HD Texture pack and manually cranking every graphics option to its highest available setting, which Shadow of Mordor’s Ultra setting doesn’t actually do. The R9 295x2 consistently crashes every time I attempt to change Mordor’s resolution or graphics settings, hence the zero scores. (Ah, the joys of multi-GPU setups.)</p>\n<p>Sleeping Dogs: Definitive Edition absolutely murders graphics cards when the graphics settings are set to Extreme at high resolutions. Only the dual-GPU Radeon R9 295x2 hits 30 fps at 4K resolution, though the Fury X hangs with its Nvidia counterparts. You can view detailed results of our tests at: <a href=\"http://go.pcworld.com/furyxbench\" target=\"_self\">go.pcworld.com/furyxbench</a>.</p>\n<p>The Fury X also hangs tight with the reference GTX 980 Ti in <i>Metro Last Light Redux</i>, which we test with PhysX and the frame rate-killing SSAA options disabled. EVGA’s version of the GTX 980 Ti trumps all single-GPU comers, though the dual-GPU Radeon R9 295x2 fires on all cylinders in this title.</p>\n<p>The Fury X and reference 980 Ti are neck and neck in <i>Alien Isolation</i>, a game that scales well across all hardware types and falls under AMD’s Gaming Evolved brand.</p>\n<p>The gorgeous D<i>ragon Age: Inquisition</i> also partnered with AMD at its launch, but Nvidia’s cards maintain a clear lead. Note that the R9 295x2 apparently doesn’t have a working CrossFire profile for the game, so it drops down to using a single GPU.</p>\n<p>The same goes for <i>Sniper Elite 3</i>. Note that we didn’t have a chance to test the reference GTX 980 Ti here.</p>\n<p>We also tested the Fury X and EVGA’s 980 Ti Superclocked+ in <i>Grand Theft Auto V</i>, because the game is notorious for demanding more than 4GB of memory—HBM’s top capacity—at high resolutions.</p>\n<p>We tested the game three ways at 4K resolution. First, by cranking all the sliders and graphics settings to their highest settings, then enabling 4X MSAA and 4X reflections MSAA in order to hit , of RAM usage; then, using the same settings but disabling all MSAA to drop the memory usage to 4,029MB, just under the Fury X’s limit; and then by testing the Fury X’s chops at normal graphics settings with MSAA disabled, which consumes 1,985MB of memory. (We didn’t have time to benchmark any other cards, alas.)</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0097-012/3481-1-eng-GB/f0097-012.jpg\" width=\"591\" height=\"360\"  style=\"border: 0px  ;\" alt=\"f0097-01\" title=\"f0097-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>The EVGA card pounds the Fury X here—no wonder <i>GTA V</i> wasn’t included in the reviewer’s guide benchmarks AMD provided for the Fury X. But the frame rate averages alone don’t show the full experience: When <i>GTA V</i> was pushed to consume more memory than the Fury X has on board, the experience became extremely stuttery, choppy, and graphically glitchy as the card offloaded duties to system memory, which is far slower than HBM.</p>\n<p>That’s to be expected when a game’s memory use exceeds the on-board capabilities of a graphics card, however, which was a big part of the reason gamers were in such a tizzy over the GTX 970’s segmented memory setup earlier this year, in which the last 0.5GB of the card’s 4GB of RAM performs much slower than the rest.</p>\n<p>I also tested the systems using three synthetic, but well-respected benchmarking tools: 3DMark’s Fire Strike and Fire Strike Ultra, as well as Unigine’s Valley. As AMD promised, the Fury X comes out ahead of the reference GTX 980 Ti in Fire Strike and Fire Strike Ultra, beating even the EVGA variant at the former, perhaps due to HBM’s speed—though the tables are turned in the Valley results. (See Fire Strike and Fire Strike Ultra test result charts at: <a href=\"http://go.pcworld.com/furyxbench\" target=\"_self\">go.pcworld.com/furyxbench</a>.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0098-012/3474-1-eng-GB/f0098-012.jpg\" width=\"591\" height=\"639\"  style=\"border: 0px  ;\" alt=\"f0098-01\" title=\"f0098-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>To test power and thermal information, I run the grueling Furmark benchmark for 15 minutes, taking temperature information at the end using Furmark’s built-in tool and double-checking it with SpeedFan. Power is measured on a whole-system basis, instead of the GPU alone, by plugging the PC into a Watts Up meter rather than the wall socket.</p>\n<p>As you can see, the Fury X may technically need only 275W for what AMD calls “typical gaming scenarios” but it draws much, much more under Furmark’s worst-case scenario—nearly as much as two GTX 980s (not Ti’s) in SLI. It drew even more power than the dual-GPU Radeon 295x2.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0099-012/3467-1-eng-GB/f0099-012.jpg\" width=\"591\" height=\"713\"  style=\"border: 0px  ;\" alt=\"f0099-01\" title=\"f0099-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0100-012/3460-1-eng-GB/f0100-012.jpg\" width=\"591\" height=\"643\"  style=\"border: 0px  ;\" alt=\"f0100-01\" title=\"f0100-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>On the positive side, the Fury X runs extremely cool, hitting 56 degrees Celsius max after several hours of overclocking. There would be plenty of room for overclocking… if the chip itself overclocked worth a damn.</p>\n<h3><b>Bottom line</b></h3><p>So there you have it: Between the new Fiji GPU and the inclusion of HBM, AMD’s Radeon R9 Fury X enters the rarefied air of single-GPU cards capable enough to play games at 4K resolutions with high graphics detail settings enabled—an exclusive club containing only it, the GTX 980 Ti, and the Titan X. (Like the Titan X and 980 Ti, the Fury X struggles to hit a full 60fps at 4K/high, however, so if you opt to pick one up you should consider picking up a new 4K FreeSync monitor to go with it.)</p>\n<p>One more time: The Fury X kicks ass! Both technically and aesthetically. AMD needed a hit, and the Fury X is sure to be one with Team Red enthusiasts.</p>\n<p>That said, it’s hard not to feel a bit disappointed about some aspects of the card—though that may have to do more with AMD’s failure to manage expectations for it.</p>\n<p>After hearing about HBM’s lofty technical numbers for months, it’s disappointing to see little to no pure gaming benefits from all that bandwidth. After seeing the tech specs and hearing AMD’s Joe Macri wax poetic about the Fury X’s overclocking potential, it’s majorly disappointing to see it fail so hard on that front, crappy silicon lottery draw or no. And while 6GB of RAM is still overkill for the vast majority of today’s games, it’s disappointing to see the Fury X limited to just 4GB of capacity when some of today’s games are starting to blow through that at the 4K resolution that AMD’s new flagship is designed for, as evidenced by our GTA V results.</p>\n<p>The timely arrival of EVGA’s custom GTX 980 Ti, which beats both AMD and Nvidia’s reference flagships in raw benchmarks, also takes some of the wind out of the Fury X’s sails—wind that can’t be countered by AMD’s own hardware partners, because the Fury X is limited to reference designs alone.</p>\n<p>No, the Fury X isn’t the Titan-killer that Team Red fans hoped it would be—but it is a GTX 980 Ti equal. This is nothing short of a powerful, thoughtful graphics card that once again puts AMD Radeon on equal footing with Nvidia’s gaming finest. Being one of the most powerful graphics cards ever created is nothing to sneeze at, especially when AMD wrapped it all up in such a lovingly designed package.</p>\n<p>AMD’s Radeon R9 Fury X kicks ass…even if it doesn’t make Nvidia’s high-end offerings obsolete.</p>\n","layout":{"landscape":{"id":"am-landscape-18","link":"rr_article_02-l.twig"},"portrait":{"id":"am-portrait-18","link":"rr_article_02.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381031.8922","name":"f0088-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0088-012/3544-1-eng-GB/f0088-012_story_img_size_768x0.jpg","portrait":true,"width":"1157","height":"768","legacy_id":"475","is_default":true},{"id":"zinio_100340926_image_0_1439381031.8922","name":"f0088-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0088-012/3544-1-eng-GB/f0088-012_story_img_size_768x0.jpg","portrait":false,"width":"1157","height":"768","legacy_id":"475","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_12_1439381024.4583","name":"f0100-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0100-012/3460-1-eng-GB/f0100-012.jpg","portrait":true,"width":"591","height":"643","legacy_id":"463"},{"id":"zinio_100340926_image_12_1439381024.4583","name":"f0100-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0100-012/3460-1-eng-GB/f0100-012.jpg","portrait":false,"width":"591","height":"643","legacy_id":"463"},{"id":"zinio_100340926_image_11_1439381025.0541","name":"f0099-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0099-012/3467-1-eng-GB/f0099-012.jpg","portrait":true,"width":"591","height":"713","legacy_id":"464"},{"id":"zinio_100340926_image_11_1439381025.0541","name":"f0099-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0099-012/3467-1-eng-GB/f0099-012.jpg","portrait":false,"width":"591","height":"713","legacy_id":"464"},{"id":"zinio_100340926_image_10_1439381025.7056","name":"f0098-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0098-012/3474-1-eng-GB/f0098-012.jpg","portrait":true,"width":"591","height":"639","legacy_id":"465"},{"id":"zinio_100340926_image_10_1439381025.7056","name":"f0098-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0098-012/3474-1-eng-GB/f0098-012.jpg","portrait":false,"width":"591","height":"639","legacy_id":"465"},{"id":"zinio_100340926_image_9_1439381026.3194","name":"f0097-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0097-012/3481-1-eng-GB/f0097-012.jpg","portrait":true,"width":"591","height":"360","legacy_id":"466"},{"id":"zinio_100340926_image_9_1439381026.3194","name":"f0097-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0097-012/3481-1-eng-GB/f0097-012.jpg","portrait":false,"width":"591","height":"360","legacy_id":"466"},{"id":"zinio_100340926_image_8_1439381026.8936","name":"f0096-01","source":"","caption":"<p><b>AMD Radeon</b> Fury X with split view.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0096-012/3488-1-eng-GB/f0096-012.jpg","portrait":true,"width":"510","height":"298","legacy_id":"467"},{"id":"zinio_100340926_image_8_1439381026.8936","name":"f0096-01","source":"","caption":"<p><b>AMD Radeon</b> Fury X with split view.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0096-012/3488-1-eng-GB/f0096-012.jpg","portrait":false,"width":"510","height":"298","legacy_id":"467"},{"id":"zinio_100340926_image_7_1439381027.6329","name":"f0095-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0095-012/3495-1-eng-GB/f0095-012.jpg","portrait":true,"width":"591","height":"806","legacy_id":"468"},{"id":"zinio_100340926_image_7_1439381027.6329","name":"f0095-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0095-012/3495-1-eng-GB/f0095-012.jpg","portrait":false,"width":"591","height":"806","legacy_id":"468"},{"id":"zinio_100340926_image_6_1439381028.3468","name":"f0093-01","source":"","caption":"<p><b>AMD Radeon</b> Fury X with cooler.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0093-012/3502-1-eng-GB/f0093-012.jpg","portrait":true,"width":"410","height":"343","legacy_id":"469"},{"id":"zinio_100340926_image_6_1439381028.3468","name":"f0093-01","source":"","caption":"<p><b>AMD Radeon</b> Fury X with cooler.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0093-012/3502-1-eng-GB/f0093-012.jpg","portrait":false,"width":"410","height":"343","legacy_id":"469"},{"id":"zinio_100340926_image_5_1439381028.95","name":"f0092-02","source":"","caption":"<p><b>The AMD</b> Radeon R9 Fury X’s technical specifications.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0092-02/3509-1-eng-GB/f0092-022.jpg","portrait":true,"width":"419","height":"481","legacy_id":"470"},{"id":"zinio_100340926_image_5_1439381028.95","name":"f0092-02","source":"","caption":"<p><b>The AMD</b> Radeon R9 Fury X’s technical specifications.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0092-02/3509-1-eng-GB/f0092-022.jpg","portrait":false,"width":"419","height":"481","legacy_id":"470"},{"id":"zinio_100340926_image_4_1439381029.5272","name":"f0092-01","source":"","caption":"<p><b>See the</b> GPU Tach LEDs just above the two 8-pin power connectors?</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0092-012/3516-1-eng-GB/f0092-012.jpg","portrait":true,"width":"434","height":"233","legacy_id":"471"},{"id":"zinio_100340926_image_4_1439381029.5272","name":"f0092-01","source":"","caption":"<p><b>See the</b> GPU Tach LEDs just above the two 8-pin power connectors?</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0092-012/3516-1-eng-GB/f0092-012.jpg","portrait":false,"width":"434","height":"233","legacy_id":"471"},{"id":"zinio_100340926_image_3_1439381030.0915","name":"f0091-01","source":"","caption":"<p><b>AMD’s</b> Fiji GPU.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0091-012/3523-1-eng-GB/f0091-012.jpg","portrait":true,"width":"420","height":"285","legacy_id":"472"},{"id":"zinio_100340926_image_3_1439381030.0915","name":"f0091-01","source":"","caption":"<p><b>AMD’s</b> Fiji GPU.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0091-012/3523-1-eng-GB/f0091-012.jpg","portrait":false,"width":"420","height":"285","legacy_id":"472"},{"id":"zinio_100340926_image_2_1439381030.7114","name":"f0090-01","source":"","caption":"<p><b>HBM space</b> savings over GDDR5.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0090-012/3530-1-eng-GB/f0090-012.jpg","portrait":true,"width":"590","height":"317","legacy_id":"473"},{"id":"zinio_100340926_image_2_1439381030.7114","name":"f0090-01","source":"","caption":"<p><b>HBM space</b> savings over GDDR5.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0090-012/3530-1-eng-GB/f0090-012.jpg","portrait":false,"width":"590","height":"317","legacy_id":"473"},{"id":"zinio_100340926_image_1_1439381031.2617","name":"f0089-01","source":"","caption":"<p><b>A diagram</b> of AMD’s HBM implementation.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0089-012/3537-1-eng-GB/f0089-012.jpg","portrait":true,"width":"736","height":"319","legacy_id":"474"},{"id":"zinio_100340926_image_1_1439381031.2617","name":"f0089-01","source":"","caption":"<p><b>A diagram</b> of AMD’s HBM implementation.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0089-012/3537-1-eng-GB/f0089-012.jpg","portrait":false,"width":"736","height":"319","legacy_id":"474"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"15","folio_number":"88","folio_numbers":"88,89,90,91,92,93,94,95,96,97,98,99,100,101","pdf_page_index":"88","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0088-012/3544-1-eng-GB/f0088-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"462","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381033.171","title":"Tested: AMD’s Frame Rate Target Control delivers real benefits for Radeon gamers","sub_title":"","author":[{"id":"0","name":"JASON EVANGELHO","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"Tested: AMD’s Frame Rate Target Control delivers real benefits for Radeon gamers","intro":"","body":"<p class=\"byline\"><b>BY JASON EVANGELHO</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0102-012/3601-1-eng-GB/f0102-012.jpg\" width=\"873\" height=\"508\"  style=\"border: 0px  ;\" alt=\"f0102-01\" title=\"f0102-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>F</b>or years, AMD has prioritized raw graphics processing horsepower over things like power efficiency and quieter operation. Then Nvidia’s Maxwell architecture came along and proved that video cards could dominate the benchmarks while still sipping power. With the launch of the new Radeon Fury X and Radeon R300 series, AMD has responded to community criticism and competitive heat with Frame Rate Targeting Control, a meaningful feature that has a serious impact on daily gaming sessions.</p>\n<p>Frame Rate Target Control (FRTC) is a new option in AMD’s Catalyst Control Center that lets you set a maximum frame rate between 55 frames per second and 95 frames per second (fps) for the majority of DirectX 10 and DirectX 11 games. The message from AMD is that FRTC is a triple threat of benefits: You’ll dramatically reduce your video card’s power consumption, decrease fan noise, and lower the operating temps of your GPU.</p>\n<p>Obviously we had to put those claims to the test.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0103-012/3594-1-eng-GB/f0103-012.jpg\" width=\"380\" height=\"361\"  style=\"border: 0px  ;\" alt=\"f0103-01\" title=\"f0103-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The Frame Rate</b> Target Control options in AMD’s Catalyst Control Center.</p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>Why AMD’s Frame Rate Targeting Control exists</b></h3><p>Wait, back up. Why on Gaben’s green earth would we PC gamers—who are addicted to stunning eye candy and smooth-as-silk frame rates— want to limit our fps? Well, there are a ton of games out there that hit super-high frame rates on modern video cards. Your PC is effectively throwing them away and needlessly taxing your video card on three fronts: Power, noise, and temperature. This wasteful behavior prompted AMD to design FRTC.</p>\n<p>Saving a few bucks on your power bill is likely lower on the priority list, but the dog days of summer and scorching GPU temperatures don’t mix. Less heat on your card means less stress, and less stress means a longer, healthier lifespan for your hardware. Plus, a reduction in noise output from our video cards mean more immersion in our games.</p>\n<p>The need for FRTC made itself abundantly clear when I booted up <i>Civilization: Beyond Earth</i> and noticed that literally thousands of frames were being wasted in the menus. Per second. Being a fairly lightweight game, my fps spiked north of 2,000 inside the menus. I was reasonably startled when I discovered how much needless electricity that was consuming, and the difference it made to GPU temperature and overall noise.</p>\n<p>Even during normal gameplay, though, the advent of AMD’s FreeSync (<a href=\"http://go.pcworld.com/amdfreesync\" target=\"_self\">go.pcworld.com/amdfreesync</a>) has reduced the need for insanely high frame rates. The bottom line: Constraining your frame rate often has a negligible impact on the overall gameplay experience, and as you’ll see in a minute, the benefits to doing so might be worth pursuing.</p>\n<h3><b>Frame Rate Targeting Control tested</b></h3><p>We rounded up AMD’s new flagship Radeon Fury X and a Sapphire Tri-X Radeon 390x to observe FRTC’s impact on both liquid-cooled and traditional air-cooled video cards. We then fired up <i>Dirt Rally</i>, <i>BioShock Infinite</i>, and <i>Civilization: Beyond Earth</i> at 1440p and measured minimum and maximum system power draw levels with FRTC off, capped at 55 fps, and capped at 75 fps.</p>\n<p>To get a good bead on any noise level and GPU temperature improvements, we ran the Heaven Valley benchmark in 15-minute loops and took note of peak decibel levels and temps under load once the cards were nice and warmed up.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0104-012/3587-1-eng-GB/f0104-012.jpg\" width=\"591\" height=\"436\"  style=\"border: 0px  ;\" alt=\"f0104-01\" title=\"f0104-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0105-012/3580-1-eng-GB/f0105-012.jpg\" width=\"591\" height=\"467\"  style=\"border: 0px  ;\" alt=\"f0105-01\" title=\"f0105-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>With FRTC off and Heaven Valley set to Medium quality at 1440p, frame rates ranged from 75 fps all the way up to 120 fps, depending on scene complexity. What happens when we put a leash on those frames? The already-cool Fury X sees a 15-percent temperature reduction, and Sapphire’s air-cooled 390x reaps the identical benefit, dropping from 71 degrees Celsius down to 60 degrees Celsius.</p>\n<p>No one enjoys a noisy graphics card whirring away in their chassis, which is why it’s awesome to see that FRTC has notable influence over noise levels. Sapphire’s 390x starts off reasonably quiet, but with FRTC capped at 55 fps (currently the lowest setting possible), it dives from 66dB to 59dB. On the surface that might seem inconsequential, but decibels are measured in increasing magnitudes of intensity. This translates to a card that isn’t merely 7dB quieter—it’s 1.6x quieter.</p>\n<p>So how about AMD’s power consumption claim? Does trimming the frame-rate fat really result in less system power pulled from the wall? It does indeed.</p>\n<p>Take a look at that <i>BioShock Infinite</i> chart, especially the Fury X results. It’s a power hog with its frame rate left unencumbered (in the low to mid 100s). The minimum amount of power drawn from the wall while running with FRTC off is higher than the maximum power draw with FRTC set to 55 fps. All told, it’s a healthy 34 percent reduction in wattage at the wall. Other high-frame-rate titles like <i>Civilization: Beyond Earth</i> and <i>Dirt Rally</i> exhibit similar—if a bit more minor— energy savings.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0106-012/3573-1-eng-GB/f0106-012.jpg\" width=\"591\" height=\"580\"  style=\"border: 0px  ;\" alt=\"f0106-01\" title=\"f0106-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><h3><b>Bottom line</b></h3><p>So with a simple Catalyst Control Center tweak that taps into Radeon 300 series graphics cards and AMD’s Fury lineup, we see a meaningful set of benefits. AMD’s Frame Rate Target Control makes your PC gaming sessions more enjoyable by turning down the ambient volume, dropping the degrees, saving you a few bucks at the wall, and likely extending the life of your video card by removing some unnecessary stress.</p>\n<p>There’s one minor quibble worth pointing out. Originally we wanted to test Blizzard’s <i>Heroes of the Storm</i>, but found that FRTC had no effect on it. We then bounced over to <i>Diablo III</i>, and FRTC was once again ineffective. At this point we suspect it’s a glitch with <a href=\"http://Battle.net\" target=\"_self\">Battle.net</a> titles, at the very least within our test environment. An inquiry to AMD has gone unanswered as of this writing.</p>\n<p class=\"pullQuote\">We’ve been impressed with Frame Rate Target Control while thoroughly testing it over the past few days.</p>\n<p>That said, we’ve been impressed with Frame Rate Target Control. The experience is augmented even further when you incorporate one of AMD’s FreeSync panels, which allows your display to dynamically sync its refresh rate with your GPU, eliminating screen tearing and input lag from the equation. But with or without FreeSync, FRTC is a very welcome new feature in AMD’s software ecosystem.</p>\n<p>Update: After our tests were completed, AMD released Catalyst 15.7 WHQL (<a href=\"http://go.pcworld.com/amdcatalyst157\" target=\"_self\">go.pcworld.com/amdcatalyst157</a>) drivers which extended both FRTC and AMD’s virtual super resolution to the vast majority of Radeon R200-series and Radeon R00-series graphics cards, as well.</p>\n","layout":{"landscape":{"id":"am-landscape-21","link":"rr_secondary-l.twig"},"portrait":{"id":"am-portrait-21","link":"rr_secondary.twig"}},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381035.5487","name":"f0102-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0102-012/3601-1-eng-GB/f0102-012_story_img_size_768x0.jpg","portrait":true,"width":"1320","height":"768","legacy_id":"482","is_default":true},{"id":"zinio_100340926_image_0_1439381035.5487","name":"f0102-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0102-012/3601-1-eng-GB/f0102-012_story_img_size_768x0.jpg","portrait":false,"width":"1320","height":"768","legacy_id":"482","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_4_1439381033.3462","name":"f0106-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0106-012/3573-1-eng-GB/f0106-012.jpg","portrait":true,"width":"591","height":"580","legacy_id":"478"},{"id":"zinio_100340926_image_4_1439381033.3462","name":"f0106-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0106-012/3573-1-eng-GB/f0106-012.jpg","portrait":false,"width":"591","height":"580","legacy_id":"478"},{"id":"zinio_100340926_image_3_1439381033.9508","name":"f0105-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0105-012/3580-1-eng-GB/f0105-012.jpg","portrait":true,"width":"591","height":"467","legacy_id":"479"},{"id":"zinio_100340926_image_3_1439381033.9508","name":"f0105-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0105-012/3580-1-eng-GB/f0105-012.jpg","portrait":false,"width":"591","height":"467","legacy_id":"479"},{"id":"zinio_100340926_image_2_1439381034.5374","name":"f0104-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0104-012/3587-1-eng-GB/f0104-012.jpg","portrait":true,"width":"591","height":"436","legacy_id":"480"},{"id":"zinio_100340926_image_2_1439381034.5374","name":"f0104-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0104-012/3587-1-eng-GB/f0104-012.jpg","portrait":false,"width":"591","height":"436","legacy_id":"480"},{"id":"zinio_100340926_image_1_1439381035.0086","name":"f0103-01","source":"","caption":"<p><b>The Frame Rate</b> Target Control options in AMD’s Catalyst Control Center.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0103-012/3594-1-eng-GB/f0103-012.jpg","portrait":true,"width":"380","height":"361","legacy_id":"481"},{"id":"zinio_100340926_image_1_1439381035.0086","name":"f0103-01","source":"","caption":"<p><b>The Frame Rate</b> Target Control options in AMD’s Catalyst Control Center.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0103-012/3594-1-eng-GB/f0103-012.jpg","portrait":false,"width":"380","height":"361","legacy_id":"481"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"16","folio_number":"102","folio_numbers":"102,103,104,105,106,107","pdf_page_index":"102","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0102-012/3601-1-eng-GB/f0102-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"477","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381036.7103","title":"Batman: Arkham Knight: How bad are the issues? Pretty bad.","sub_title":"","author":[{"id":"0","name":"GORDON MAH UNG","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"Batman: Arkham Knight: How bad are the issues? Pretty bad.","intro":"","body":"<p class=\"byline\"><b>BY GORDON MAH UNG</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0108-012/3686-1-eng-GB/f0108-012.jpg\" width=\"873\" height=\"562\"  style=\"border: 0px  ;\" alt=\"f0108-01\" title=\"f0108-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p><b>A</b>fter playing the<b> </b><i>Batman: Arkham Knight</i> game on several PCs, it’s obvious why WB Games decided to suspend sales.</p>\n<p>PC gamers, we should have expected this.</p>\n<p>Despite this year being <i>our</i> year, with our own dedicated PC-gaming show at E3, <i>Batman: Arkham Knight</i> (<a href=\"http://batmanarkhamknight.com\" target=\"_self\">batmanarkhamknight.com</a>) is an unkindly reminder of where we stand with game developers: Console gamers got a brilliantly crafted game while we’re stuck with a standard-issue, glitch-filled port.</p>\n<p>At least that’s what nearly 8,000 and counting people on Steam are saying about this brand-new game. The torches and pitchforks became numerous enough that WB Games made the nearly unprecedented decision to indefinitely suspended sales of the PC version of <i>Arkham Knight</i> until its problems can be resolved.</p>\n<p>As one of the hottest games of the season, <i>Batman: Arkham Knight</i> had big marketing dollars behind it and a strong Metacritic score of 89 filling its sails. Every one of those critics, however, reviewed the PlayStation 4 version. No reviews of the PC port were published before the game was shipped.</p>\n<p>With thousands of people who purchased the PC version filing complaints about texture flashing, crashing, stuttering, and terrible frame rates, <i>Batman: Arkham Knight</i> is what’s technically called a hot stinking mess.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0109-01/3679-1-eng-GB/f0109-012.jpg\" width=\"426\" height=\"224\"  style=\"border: 0px  ;\" alt=\"f0109-01\" title=\"f0109-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Want to know</b> what <i>Batman: Arkham Knight</i> looks like with 4-way Titan X in SLI and a Core i7-5960X overclocked to 4.5GHz? This 4K resolution error message.</p>\n</figcaption>\n    \n    \n    \n    </div><p>To find out just how bad it was, I fired up <i>Batman: Arkham Knight</i> on the most powerful gaming PC I had on hand: a 4-way SLI GeForce Titan X rig with a Core i7-5960X overclocked to 4.5GHz, RAIDed SSDs, and 16GB of DDR4/2666 RAM. What does $11,000 worth of fire-breathing, meat-eating metal get you? How about 30 frames per second? ( <i>Insert needle-scratch sound</i>.)</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0109-02/3672-1-eng-GB/f0109-022.jpg\" width=\"873\" height=\"495\"  style=\"border: 0px  ;\" alt=\"f0109-02\" title=\"f0109-02\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>Watch the video at <a href=\"http://go.pcworld.com/arkham\" target=\"_self\">go.pcworld.com/arkham</a> knightvid</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0110-012/3665-1-eng-GB/f0110-012.jpg\" width=\"731\" height=\"409\"  style=\"border: 0px  ;\" alt=\"f0110-01\" title=\"f0110-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Setting PhysX</b> to run on GPU number four would at least get the game to run for me.</p>\n</figcaption>\n    \n    \n    \n    </div><p>And no, that’s not at surround 4K or straightforward 4K resolution. WB Games decided to lock Arkham Knight down to 30 fps no matter <i>what</i> hardware you’re running. Whether it’s a GeForce GTX 960 or a four-way GeForce Titan X setup, this game will max out at 30 frames per second running on a PC.</p>\n<p>The good news is there’s a workaround, but you’ll need to dig into an INI file rather than, oh, use an in-game switch.</p>\n<p>Backup your game first, and then dig into C:\\ProgramFiles(x86)\\ Steam\\ steamapps\\common\\Batman Arkham Knight\\BMGame\\ Config, and then open BmSystemSettings. ini in Notepad and look for the line that says MaxFPS=30.000000. Changing that to either 60 or 120 will allow the game to run at higher frame rates.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0111-012/3658-1-eng-GB/f0111-012.jpg\" width=\"395\" height=\"284\"  style=\"border: 0px  ;\" alt=\"f0111-01\" title=\"f0111-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>You can override</b> the 30 fps lock in <i>Batman: Arkham Knight</i> by editing one of its .INI files.</p>\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0111-02/3651-1-eng-GB/f0111-022.jpg\" width=\"591\" height=\"376\"  style=\"border: 0px  ;\" alt=\"f0111-02\" title=\"f0111-02\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>What's wrong</b> with this picture? We don't know, and maybe that’s why WB Games pulled the PC version of <i>Batman: Arkham Knight.</i></p>\n</figcaption>\n    \n    \n    \n    </div><h3><b>But then there’s crashing too</b></h3><p>On my 4-way system, I initially ran the game at 1080p to see if issues would crop up; but once I’d changed that . INI file, I decided to let it run in its full 4K glory: I was immediately greeted with the game crashing as soon as I tried to run it in benchmark mode. After that crash, it never went back to working without mucking around. Even setting the .INI file back to a maximum of 30 fps didn’t help.</p>\n<p>Through this mucking around, I determined that the only way to get it to run was to follow WB Games’ advice (<a href=\"http://go.pcworld.com/arkhampcupdate\" target=\"_self\">go.pcworld.com/arkhampcupdate</a>) to dedicate one of my GPUs to PhysX to help “performance.” It didn’t help performance in my experience, but it at least made it so I could play the game. All of my issues, mind you, were with the recommended Nvidia 353.30 GameReady driver that technically supports SLI. More on this later.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0112-012/3644-1-eng-GB/f0112-012.jpg\" width=\"394\" height=\"268\"  style=\"border: 0px  ;\" alt=\"f0112-01\" title=\"f0112-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>The smoke</b> in this scene looks dramatically better with GameWorks fog and paper effects and PhysX enabled.</p>\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0112-02/3637-1-eng-GB/f0112-022.jpg\" width=\"394\" height=\"267\"  style=\"border: 0px  ;\" alt=\"f0112-02\" title=\"f0112-02\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>You can love or hate</b> GameWorks, but having the smoke effects turned off makes the Batmobile’s burnout look wimpy. This would get you negative feedback at an Oakland sideshow.</p>\n</figcaption>\n    \n    \n    \n    </div><p>Letting the Nvidia driver automatically select the GPU to run PhysX on would cause a crash. And in the bizarre column, depending on which GPU you ran, PhysX would limit your SLI support. Run PhysX on GPU number one or two and you get no SLI support whatsoever. Run it on GPU number four and you get SLI or two GPU’s only. Running it on GPU number three though, would get you tri-SLI at least, with only occasional crashes to the desktop.</p>\n<p>One reliable way I could get the game to run on all four GPUs, at least according to the Nvidia control panel, was to run PhysX on the CPU. But that turned off the game’s Interactive Smoke and Paper Debris settings. And as controversial as GameWorks and PhysX are to gamers who run AMD video cards, the effects in <i>Batman: Arkham Knight</i> are beautiful.</p>\n<p>It’s only after seeing <i>Batman: Arkham Knight</i> with the smoke and paper effects on and off that you realize what you’re missing. It’s almost enough to make someone who doesn’t like proprietary technology forgive the game for using those Nvidia-only features. I mean, that smoke is <i>wondrous</i>. Watch the video and you can see it curl as the Batmobile peels down the street.</p>\n<p>The game’s performance is another head-scratcher. Let me remind you, I’m running the game on an 8-core Core-i7 rig with four water-cooled Titan X cards. This rig pushes <i>Middle-earth: Shadow of Mordor,</i> with its HD textures at 4K resolution, at 100 fps. It plays <i>Tomb Raider</i> at 4K on Ultimate at nearly 170 fps. With <i>Batman Arkham Knight</i>, the in-game benchmark reported a dismally low frame rate in the 40’s. Even crazier, I wasn’t seeing any SLI scaling at all. One Titan X, two Titan X, or four didn’t move the needle. <i>All</i> of my performance tests were in the mid- to low 40s. I tried the latest GeForce Experience optimizations and multiple reboots with nary a difference.</p>\n<p>What’s up? I spoke with Nvidia officials who said they’re trying to figure out what my problem is, because they are seeing scaling internally. I’ll report back once we figure it out.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0113-012/3630-1-eng-GB/f0113-012.jpg\" width=\"262\" height=\"293\"  style=\"border: 0px  ;\" alt=\"f0113-01\" title=\"f0113-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><h3><b>What about AMD?</b></h3><p>Remember, this is the game running on Nvidia hardware, which traditionally has a leg up in performance and stability over AMD GPUs for this franchise. Many AMD users have also reported issues running the game. Even worse, the section of WB Games’ FAQ that discusses running the game on both AMD and Nvidia hardware reads like the fine print for a prescription drug that hasn’t yet passed FDA trials.</p>\n<p>The craziest part of <i>Batman: Arkham Knight</i> is that when it <i>does</i> run, it seems to run fine. In addition to running it on that Big Bertha Titan X system, I also ran it on Asus’ new ROG gaming laptop, which is outfitted with a GeForce GTX 980M. It ran just fine, with frame rates on the single card in the 60 fps range. That’s at 1080p resolution, mind you, but it makes it even more puzzling that the game ran so poorly on a desktop PC with a single Titan X.</p>\n<p><b>Bottom line:</b> WB Games made the right move in suspending sales.</p>\n","layout":{},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381042.0799","name":"f0108-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0108-012/3686-1-eng-GB/f0108-012_default_ipad_portrait.jpg","portrait":true,"width":"768","height":"494","legacy_id":"493","is_default":true},{"id":"zinio_100340926_image_0_1439381042.0799","name":"f0108-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0108-012/3686-1-eng-GB/f0108-012_default_ipad_landscape.jpg","portrait":false,"width":"873","height":"562","legacy_id":"493","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_8_1439381036.8695","name":"f0113-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0113-012/3630-1-eng-GB/f0113-012.jpg","portrait":true,"width":"262","height":"293","legacy_id":"485"},{"id":"zinio_100340926_image_8_1439381036.8695","name":"f0113-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0113-012/3630-1-eng-GB/f0113-012.jpg","portrait":false,"width":"262","height":"293","legacy_id":"485"},{"id":"zinio_100340926_image_7_1439381037.6616","name":"f0112-02","source":"","caption":"<p><b>You can love or hate</b> GameWorks, but having the smoke effects turned off makes the Batmobile’s burnout look wimpy. This would get you negative feedback at an Oakland sideshow.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0112-02/3637-1-eng-GB/f0112-022.jpg","portrait":true,"width":"394","height":"267","legacy_id":"486"},{"id":"zinio_100340926_image_7_1439381037.6616","name":"f0112-02","source":"","caption":"<p><b>You can love or hate</b> GameWorks, but having the smoke effects turned off makes the Batmobile’s burnout look wimpy. This would get you negative feedback at an Oakland sideshow.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0112-02/3637-1-eng-GB/f0112-022.jpg","portrait":false,"width":"394","height":"267","legacy_id":"486"},{"id":"zinio_100340926_image_6_1439381038.2434","name":"f0112-01","source":"","caption":"<p><b>The smoke</b> in this scene looks dramatically better with GameWorks fog and paper effects and PhysX enabled.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0112-012/3644-1-eng-GB/f0112-012.jpg","portrait":true,"width":"394","height":"268","legacy_id":"487"},{"id":"zinio_100340926_image_6_1439381038.2434","name":"f0112-01","source":"","caption":"<p><b>The smoke</b> in this scene looks dramatically better with GameWorks fog and paper effects and PhysX enabled.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0112-012/3644-1-eng-GB/f0112-012.jpg","portrait":false,"width":"394","height":"268","legacy_id":"487"},{"id":"zinio_100340926_image_5_1439381038.8716","name":"f0111-02","source":"","caption":"<p><b>What's wrong</b> with this picture? We don't know, and maybe that’s why WB Games pulled the PC version of <i>Batman: Arkham Knight.</i></p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0111-02/3651-1-eng-GB/f0111-022.jpg","portrait":true,"width":"591","height":"376","legacy_id":"488"},{"id":"zinio_100340926_image_5_1439381038.8716","name":"f0111-02","source":"","caption":"<p><b>What's wrong</b> with this picture? We don't know, and maybe that’s why WB Games pulled the PC version of <i>Batman: Arkham Knight.</i></p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0111-02/3651-1-eng-GB/f0111-022.jpg","portrait":false,"width":"591","height":"376","legacy_id":"488"},{"id":"zinio_100340926_image_4_1439381039.4023","name":"f0111-01","source":"","caption":"<p><b>You can override</b> the 30 fps lock in <i>Batman: Arkham Knight</i> by editing one of its .INI files.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0111-012/3658-1-eng-GB/f0111-012.jpg","portrait":true,"width":"395","height":"284","legacy_id":"489"},{"id":"zinio_100340926_image_4_1439381039.4023","name":"f0111-01","source":"","caption":"<p><b>You can override</b> the 30 fps lock in <i>Batman: Arkham Knight</i> by editing one of its .INI files.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0111-012/3658-1-eng-GB/f0111-012.jpg","portrait":false,"width":"395","height":"284","legacy_id":"489"},{"id":"zinio_100340926_image_3_1439381040.0526","name":"f0110-01","source":"","caption":"<p><b>Setting PhysX</b> to run on GPU number four would at least get the game to run for me.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0110-012/3665-1-eng-GB/f0110-012.jpg","portrait":true,"width":"731","height":"409","legacy_id":"490"},{"id":"zinio_100340926_image_3_1439381040.0526","name":"f0110-01","source":"","caption":"<p><b>Setting PhysX</b> to run on GPU number four would at least get the game to run for me.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0110-012/3665-1-eng-GB/f0110-012.jpg","portrait":false,"width":"731","height":"409","legacy_id":"490"},{"id":"zinio_100340926_image_2_1439381040.7409","name":"f0109-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0109-02/3672-1-eng-GB/f0109-022.jpg","portrait":true,"width":"873","height":"495","legacy_id":"491"},{"id":"zinio_100340926_image_2_1439381040.7409","name":"f0109-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0109-02/3672-1-eng-GB/f0109-022.jpg","portrait":false,"width":"873","height":"495","legacy_id":"491"},{"id":"zinio_100340926_image_1_1439381041.44","name":"f0109-01","source":"","caption":"<p><b>Want to know</b> what <i>Batman: Arkham Knight</i> looks like with 4-way Titan X in SLI and a Core i7-5960X overclocked to 4.5GHz? This 4K resolution error message.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0109-01/3679-1-eng-GB/f0109-012.jpg","portrait":true,"width":"426","height":"224","legacy_id":"492"},{"id":"zinio_100340926_image_1_1439381041.44","name":"f0109-01","source":"","caption":"<p><b>Want to know</b> what <i>Batman: Arkham Knight</i> looks like with 4-way Titan X in SLI and a Core i7-5960X overclocked to 4.5GHz? This 4K resolution error message.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0109-01/3679-1-eng-GB/f0109-012.jpg","portrait":false,"width":"426","height":"224","legacy_id":"492"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"17","folio_number":"108","folio_numbers":"108,109,110,111,112,113","pdf_page_index":"108","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0108-012/3686-1-eng-GB/f0108-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"484","main_section_id":"9","ads":[]},{"id":"zinio_3_100340926_1439381043.4958","title":"Batman: Arkham Knight (PC): Holy squandered potential, Batman","sub_title":"","author":[{"id":"0","name":"HAYDEN DINGMAN","email":"noreply@audiencemedia.com","is_default":false}],"tag":"","strap_line":"Batman: Arkham Knight (PC): Holy squandered potential, Batman","intro":"","body":"<p class=\"byline\"><b>BY HAYDEN DINGMAN</b></p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0114-012/3785-1-eng-GB/f0114-012.jpg\" width=\"873\" height=\"630\"  style=\"border: 0px  ;\" alt=\"f0114-01\" title=\"f0114-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>UP Front: There are going to be spoilers in this review. Or, at least, a few of you may deem them spoilers—I am going to actively discuss <i>some</i> of the villains in <i>Arkham Knight</i>. By name. And a few of the plot points. Why? Because there are very specific examples that I feel embody <i>Arkham Knight</i>’s failings, and it’s easier for me to just talk through them than talk around them.</p>\n<p>Good? Good. Let’s dig in.</p>\n<h3><b>Na-na-na-na-na-na-na-na-na</b></h3><p><i>Phew</i>. Where to even <i>start</i> with <i>Arkham Knight</i>? I mean, we could take the easy route on this one and talk about how busted the PC port is. It is <i>busted</i>. I got a higher frame rate in <i>The Witcher 3</i> on Ultra than I did in <i>Arkham Knight</i>, and I don’t just mean because of the console-esque, 30-frames-per-second cap the game shipped with.</p>\n<p>You know what though? The PC version will get fixed. It might take weeks. It might take months. But I have no doubt eventually Rocksteady will fix it. Should it have been released this way in the first place? Absolutely not, and thus we’re not bothering to score this review. It is not a game in any condition to be scored. And, for that matter, it’s not even on sale anymore.</p>\n<p>The technical problems with <i>Arkham Knight</i> have been a lightning rod, though. There are so many other issues with this game that have nothing to do with its frame rate, its textures, any of that. Let’s discuss those instead.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0115-012/3778-1-eng-GB/f0115-012.jpg\" width=\"376\" height=\"286\"  style=\"border: 0px  ;\" alt=\"f0115-01\" title=\"f0115-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0115-02/3771-1-eng-GB/f0115-022.jpg\" width=\"873\" height=\"482\"  style=\"border: 0px  ;\" alt=\"f0115-02\" title=\"f0115-02\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0116-012/3764-1-eng-GB/f0116-012.jpg\" width=\"873\" height=\"496\"  style=\"border: 0px  ;\" alt=\"f0116-01\" title=\"f0116-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p class=\"pullQuote\">Everything that is great about ‘Arkham Knight’ has been lifted from Rocksteady’s previous two games.</p>\n<p>Sure, it’s fun, but <i>Arkham Knight</i> is not a great game. It is a collection of pretty great mechanics soldered onto some cringe-worthy dialogue, a pile of meaningless side missions, a decent main story, some truly illogical plot conceits, and so much forced vehicular action it’d be easy to forget this is a story about Batman.</p>\n<p>Everything that is great about <i>Arkham Knight</i> has been lifted from Rocksteady’s previous two games—the incredible <i>Arkham Asylum</i> and the slightly-less-incredible-but-stillgood <i>Arkham City</i>. Embodying Batman in <i>Arkham Knight</i> is, frankly, fantastic. The trademark Batman combat has never been more fluid. Gliding around the city is considerably less janky than it was in <i>Arkham City</i>. And there’s a new move that involves ejecting out of the Batmobile at high speed and launching yourself a mile into the air before gliding around Gotham. It looks <i>badass</i>.</p>\n<p>That is the last nice thing I am going to say about the Batmobile. See, the Batmobile is problem number one with <i>Arkham Knight</i>. Rocksteady touted the Batmobile feature a ton prior to release, and now we know why: because it’s been forced into practically every single encounter in the game. Even Riddler’s missions. Riddler now constructs race tracks. No, I am not joking.</p>\n<p>There are a few issues here. First of all, <i>THE RIDDLER NOW CONSTRUCTS RACE TRACKS</i>. This is something so magnificently stupid I can’t even fully come to grips with it.</p>\n<p>Other missions have you fighting legions and legions of “drones”— they’re tanks but they’re unmanned because Batman doesn’t kill!— until your eyes glaze over. None of these missions are particularly hard. Just tedious.</p>\n<p>But the greatest sin of the Batmobile has nothing to do with the car itself. Rather, it’s the design direction the game took once it was apparently mandated that Batman’s biggest and most inefficient gadget had to factor into practically every part of the game.</p>\n<p>One of the best ideas in <i>Arkham Asylum</i> and <i>Arkham City</i> was something I’ll refer to as the “Villain Lair.” In <i>Asylum</i>, this meant seeing how each member of Batman’s Rogues Gallery transformed their little section of Arkham—a fiefdom within Joker’s larger kingdom. <i>Arkham City</i> kept the same idea, except it expanded to villains’ owning entire buildings. “Here’s Penguin, holed up in a weird museum! Here’s the (infamous) Mr. Freeze section! Here’s Mad Hatter’s lair of Scarecrow-inspired dream sequences!”</p>\n<p class=\"pullQuote\">Riddler now constructs race tracks?!</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0117-012/3757-1-eng-GB/f0117-012.jpg\" width=\"873\" height=\"494\"  style=\"border: 0px  ;\" alt=\"f0117-01\" title=\"f0117-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0118-012/3750-1-eng-GB/f0118-012.jpg\" width=\"873\" height=\"534\"  style=\"border: 0px  ;\" alt=\"f0118-01\" title=\"f0118-01\" />\n        \t\t<figcaption style=\"display:none\">\n<p><b>Here is Penguin’s</b> big lair. Looks...not very Penguin-y.</p>\n</figcaption>\n    \n    \n    \n    </div><p><i>Arkham Knight</i> abandons this and squanders its villains, especially outside of the main story. Penguin is smuggling guns out of featureless warehouses. Firefly pulls the same “bust out of a building that’s on fire” move <i>three times</i> before deciding he’s been punched in the face enough to stay down. Man-Bat doesn’t even do <i>anything</i>—he just flies in circles until you decide to find him. Two-Face is robbing generic banks.</p>\n<p>And Deathstroke—oh, poor Deathstroke. He doesn’t even get his own unique story line. One of the most fearsome villains in the DC Universe is relegated to a fourth-tier role here, as he takes over for <i>another</i> villain you’ve already confronted. Even worse? Deathstroke’s “boss battle” is a Batmobile-led tank battle that’s literally a copy-paste of a tank battle you already played earlier in the game.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0119-01/3743-1-eng-GB/f0119-012.jpg\" width=\"512\" height=\"289\"  style=\"border: 0px  ;\" alt=\"f0119-01\" title=\"f0119-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div>\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0119-02/3736-1-eng-GB/f0119-022.jpg\" width=\"512\" height=\"289\"  style=\"border: 0px  ;\" alt=\"f0119-02\" title=\"f0119-02\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>Batman’s most iconic villains are just sort of… doing nothing at all. Farting around committing petty crimes while the entire city is on the verge of extinction. God forbid Two-Face rob a few banks while Scarecrow is threatening to <i>literally wipe Gotham off the face of the planet with fear toxin.</i></p>\n<p>It feels empty. Tedious, even. And how did we get here? The other <i>Arkham</i> games somehow managed to make even lame characters (Calendar Man) seem interesting, or like you should know something about them. Here, even the franchise’s most iconic characters come off as buffoons (at worst) or just empty filler characters (at best). There’s nothing uniquely Penguin about smuggling guns, nothing uniquely Two-Face about robbing banks. And by placing them in these settings, you also miss out on the whole “Lair” aspect. Your final fight against Two-Face takes place in a bank that’s indistinguishable from the first two he robbed. There’s nothing there that screams “Two-Face.” No clever environmental storytelling.</p>\n<p>Which is weird because the city of Gotham itself is just as over-the-top as it was in <i>Arkham City</i>. There’s neon everywhere. All the buildings teem with unique art and visual design. It’s a creative, comic book– esque take on the city and I love flying around it—but very few of these buildings actually factor into the story in any interesting way. They’re just there to look pretty while you glide/drive around.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0120-01/3729-1-eng-GB/f0120-012.jpg\" width=\"725\" height=\"406\"  style=\"border: 0px  ;\" alt=\"f0120-01\" title=\"f0120-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>And I blame it on the Batmobile. I do. <i>Arkham City</i> had the same open-world setup as <i>Arkham Knight</i>, but it played completely differently. The city was essentially an enormous hub between the actual levels. Very little of the game took place in the city itself. Instead, you flew to wherever the next mission was, <i>went inside</i>, and then explored the building often for upwards of half an hour.</p>\n<p><i>Arkham Knight</i> is so afraid of letting you be inside, because what if… what if you forget about the Batmobile? As such, probably 90 percent of the main story and 80 percent of the side missions take place in the city itself. And the rest? It’s mostly made up of quick hit-and-run beats. Two-Face’s robberies, for instance—you’re only inside for five to ten minutes, max. Then you’re kicked back onto the street.</p>\n<p>The result is a game that feels unfocused, that feels like it’s shuttling you from empty mission to empty mission and discarding all its villains. Whereas <i>Arkham City</i> felt like it had potentially too many villains, <i>Arkham Knight</i> feels like it has too few—or at least too few that matter. It’s basically Scarecrow (the main baddie) and the titular Arkham Knight. Everyone else is disposable.</p>\n<p>Luckily Scarecrow carries some of the narrative weight, thanks to an excellent, truly wonderful performance by John Noble. Unfortunately, it’s a <i>Star Wars</i> situation where you have a talented actor reading utter farce. On the other hand, he’s so menacing you can forgive the occasional plot hole or telegraphed twist.</p>\n<p>Sorry, when I said “occasional plot hole” I meant “<i>Arkham Knight</i>’s plot is silly.” Even with the spoiler tag above, I don’t want to kill the <i>whole</i> plot for you.</p>\n<p>But let’s just say there’s a point where Scarecrow announces his <i>big backup plan</i>…and it’s to cover Gotham in fear toxin. A Gotham that’s already been evacuated. A Gotham that is only populated by a handful of police, Batman, Alfred, and a whole bunch of villains.</p>\n<p>Go ahead, Scarecrow. Gas the city. See if I care.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0121-01/3722-1-eng-GB/f0121-012.jpg\" width=\"873\" height=\"482\"  style=\"border: 0px  ;\" alt=\"f0121-01\" title=\"f0121-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><h3><b>Bottom line</b></h3><p>The thing about <i>Arkham Knight</i>, about reviewing <i>Arkham Knight</i>, is I didn’t even hate the game. It’s a summer blockbuster. It’s soda and popcorn. It’s something that goes down smoothly (aside from the stupid tank sections), but at the end you’ve consumed nothing at all of value.</p>\n\n<div class=\"\">\t\t\n\n    \n        \n    \n                                                                                                                                            <img src=\"/var/site_987/storage/images/media2/images/f0122-012/3715-1-eng-GB/f0122-012.jpg\" width=\"288\" height=\"529\"  style=\"border: 0px  ;\" alt=\"f0122-01\" title=\"f0122-01\" />\n        \t\t<figcaption style=\"display:none\">\n</figcaption>\n    \n    \n    \n    </div><p>I’m not going to say that <i>Arkham Asylum</i> and <i>Arkham City</i> were particularly smart games, but they were smart <i>superhero</i> games. Take the grit of Nolan’s Batman, combine it with the eye-candy of Tim Burton’s Gotham, and you’ve got one hell of a take on the dark knight. The <i>Arkham</i> series was great because it played to Batman’s strengths—his brutality, his knack for inducing fear, his cleverness, and (most importantly) the unique and twisted personalities of his villains.</p>\n<p><i>Arkham Knight</i> doesn’t do those things. It doesn’t let Batman be Batman. It doesn’t let Batman’s villains be villainous. With the exception of a <i>single plot thread</i> it squanders two games’ worth of setup and replaces much of what I loved about the series with pointless filler. Filler I completed. Filler I even sometimes enjoyed on a purely mechanical level— crawling through vents and silently taking down henchmen as Batman is as satisfying as ever.</p>\n<p>But too often I felt like <i>Arkham Knight</i> was a professional athlete post-retirement: Bloated, unfocused, and always boasting about a really nice car.</p>\n","layout":{},"relative_links":[],"schedule":"","paywall_availability":0,"link_source":"","competition":[],"flatplan_title":"","notes":"","gutter_credit":"","other":"","image":[{"id":"zinio_100340926_image_0_1439381049.9455","name":"f0114-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0114-012/3785-1-eng-GB/f0114-012_default_ipad_portrait.jpg","portrait":true,"width":"768","height":"554","legacy_id":"506","is_default":true},{"id":"zinio_100340926_image_0_1439381049.9455","name":"f0114-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0114-012/3785-1-eng-GB/f0114-012_default_ipad_landscape.jpg","portrait":false,"width":"873","height":"630","legacy_id":"506","is_default":false}],"related_objects":{"image":[{"id":"zinio_100340926_image_10_1439381043.7279","name":"f0122-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0122-012/3715-1-eng-GB/f0122-012.jpg","portrait":true,"width":"288","height":"529","legacy_id":"496"},{"id":"zinio_100340926_image_10_1439381043.7279","name":"f0122-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0122-012/3715-1-eng-GB/f0122-012.jpg","portrait":false,"width":"288","height":"529","legacy_id":"496"},{"id":"zinio_100340926_image_9_1439381044.3501","name":"f0121-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0121-01/3722-1-eng-GB/f0121-012.jpg","portrait":true,"width":"873","height":"482","legacy_id":"497"},{"id":"zinio_100340926_image_9_1439381044.3501","name":"f0121-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0121-01/3722-1-eng-GB/f0121-012.jpg","portrait":false,"width":"873","height":"482","legacy_id":"497"},{"id":"zinio_100340926_image_8_1439381044.9754","name":"f0120-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0120-01/3729-1-eng-GB/f0120-012.jpg","portrait":true,"width":"725","height":"406","legacy_id":"498"},{"id":"zinio_100340926_image_8_1439381044.9754","name":"f0120-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0120-01/3729-1-eng-GB/f0120-012.jpg","portrait":false,"width":"725","height":"406","legacy_id":"498"},{"id":"zinio_100340926_image_7_1439381045.5677","name":"f0119-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0119-02/3736-1-eng-GB/f0119-022.jpg","portrait":true,"width":"512","height":"289","legacy_id":"499"},{"id":"zinio_100340926_image_7_1439381045.5677","name":"f0119-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0119-02/3736-1-eng-GB/f0119-022.jpg","portrait":false,"width":"512","height":"289","legacy_id":"499"},{"id":"zinio_100340926_image_6_1439381046.1275","name":"f0119-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0119-01/3743-1-eng-GB/f0119-012.jpg","portrait":true,"width":"512","height":"289","legacy_id":"500"},{"id":"zinio_100340926_image_6_1439381046.1275","name":"f0119-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0119-01/3743-1-eng-GB/f0119-012.jpg","portrait":false,"width":"512","height":"289","legacy_id":"500"},{"id":"zinio_100340926_image_5_1439381046.8125","name":"f0118-01","source":"","caption":"<p><b>Here is Penguin’s</b> big lair. Looks...not very Penguin-y.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0118-012/3750-1-eng-GB/f0118-012.jpg","portrait":true,"width":"873","height":"534","legacy_id":"501"},{"id":"zinio_100340926_image_5_1439381046.8125","name":"f0118-01","source":"","caption":"<p><b>Here is Penguin’s</b> big lair. Looks...not very Penguin-y.</p>\n","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0118-012/3750-1-eng-GB/f0118-012.jpg","portrait":false,"width":"873","height":"534","legacy_id":"501"},{"id":"zinio_100340926_image_4_1439381047.5483","name":"f0117-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0117-012/3757-1-eng-GB/f0117-012.jpg","portrait":true,"width":"873","height":"494","legacy_id":"502"},{"id":"zinio_100340926_image_4_1439381047.5483","name":"f0117-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0117-012/3757-1-eng-GB/f0117-012.jpg","portrait":false,"width":"873","height":"494","legacy_id":"502"},{"id":"zinio_100340926_image_3_1439381048.1923","name":"f0116-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0116-012/3764-1-eng-GB/f0116-012.jpg","portrait":true,"width":"873","height":"496","legacy_id":"503"},{"id":"zinio_100340926_image_3_1439381048.1923","name":"f0116-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0116-012/3764-1-eng-GB/f0116-012.jpg","portrait":false,"width":"873","height":"496","legacy_id":"503"},{"id":"zinio_100340926_image_2_1439381048.7688","name":"f0115-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0115-02/3771-1-eng-GB/f0115-022.jpg","portrait":true,"width":"873","height":"482","legacy_id":"504"},{"id":"zinio_100340926_image_2_1439381048.7688","name":"f0115-02","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0115-02/3771-1-eng-GB/f0115-022.jpg","portrait":false,"width":"873","height":"482","legacy_id":"504"},{"id":"zinio_100340926_image_1_1439381049.3481","name":"f0115-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0115-012/3778-1-eng-GB/f0115-012.jpg","portrait":true,"width":"376","height":"286","legacy_id":"505"},{"id":"zinio_100340926_image_1_1439381049.3481","name":"f0115-01","source":"","caption":"","media_annotations":"","media_creator":"","media_usage_license":"","image_url":"http://cdn-assets.ziniopro.com/var/site_987/storage/images/media2/images/f0115-012/3778-1-eng-GB/f0115-012.jpg","portrait":false,"width":"376","height":"286","legacy_id":"505"}]},"url_alias":"http://pcworld-us.audiencemedia.com","type":"story","order":"18","folio_number":"114","folio_numbers":"114,115,116,117,118,119,120,121,122","pdf_page_index":"114","thumbnail":"http://pcworld-us.audiencemedia.com/var/site_987/storage/images/media2/images/f0114-012/3785-1-eng-GB/f0114-012_tablet_story_thumbnail.jpg","color":"FFFFFF","real_id":"495","main_section_id":"9","ads":[]}],"type":null,"ads":[]}}
